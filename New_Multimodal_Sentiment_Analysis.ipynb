{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sSkERWzDL3o"
      },
      "source": [
        "# Multimodal Sentiment Analysis\n",
        "\n",
        "###Overview\n",
        "- This project performs sentiment analysis on MASAD, an open-source dataset containing ~38,000 text/image pairs.\n",
        "- We preprocess the data into cleaned text and augmented images and then load the data.\n",
        "- Our architecture is comprised of a transformer encoder, keyless attention to weight each modality, and a classification head.\n",
        "- The test accuracy of our model is roughly 94% and our F1 score is also roughly 94%, comparable to the model used in the original MASAD paper.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "###Instructions to Run Project\n",
        "1. Download the following datasets: MASAD, MASAD_SUBSET\n",
        "2. Create shortcut for both datasets in google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaHTbfoltjIl"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm\n",
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud7J6SD9t4CW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import CLIPProcessor\n",
        "import re\n",
        "import glob\n",
        "import sys\n",
        "import sklearn\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from tqdm.notebook import tqdm\n",
        "import pickle\n",
        "from transformers import get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCrEzIA7UI0T",
        "outputId": "c9523771-bd6f-4afb-a7ec-b9802d425d74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "print(f\"model will run on {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYEOPm-kE6Eo",
        "outputId": "22a89ab4-6042-419e-a722-4ad3882f7435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model will run on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfR5oK3OX3Yc"
      },
      "source": [
        "# Configuration parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUock9y1CSz1"
      },
      "outputs": [],
      "source": [
        "# Set configs for program (e.g. run w/ subset of data for faster processing & debugging)\n",
        "use_data_subset = True\n",
        "extract_text_bool = True\n",
        "generate_clip_embeddings = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB3tHYs3Qt3U"
      },
      "outputs": [],
      "source": [
        "def set_max_cell_output_height(max_height=200):\n",
        "    \"\"\" Helper function that visually limits the size of cell output blocks to reduce the amoutn of\n",
        "        scrolling required for code block output\n",
        "        Unfortuantely this cannot be set globally -- call in any functions which print long outputs\n",
        "    \"\"\"\n",
        "    from IPython.display import Javascript\n",
        "    display(Javascript(f'''google.colab.output.setIframeHeight(0, true, {{maxHeight: {max_height}}})'''))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFLDLiNBX80I"
      },
      "source": [
        "# Preprocessing Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGsf_vZTYF0_"
      },
      "source": [
        "###Accessing File Paths to Read & Process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlNpnTPgVlXV"
      },
      "outputs": [],
      "source": [
        "if use_data_subset:\n",
        "  root_dir = '/content/drive/MyDrive/MASAD_SUBSET'\n",
        "else:\n",
        "  root_dir = '/content/drive/MyDrive/MASAD/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing: Text only"
      ],
      "metadata": {
        "id": "jnbB05_69Yve"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSZfWWCsUbgH"
      },
      "outputs": [],
      "source": [
        "# Goal: Create a .csv with filepaths for both types and labels\n",
        "# We need:\n",
        "# 1. im paths\n",
        "# 2. text paths\n",
        "# 3. labels\n",
        "image_paths = []\n",
        "text_paths = []\n",
        "labels = []\n",
        "\n",
        "splits = ['train', 'test']\n",
        "sentiments = ['negative', 'positive']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Create a basic .csv where each row contains a valid image filepath in Google Drive, its corresponding valid text filepath, and the sentiment label of the pair."
      ],
      "metadata": {
        "id": "fGE5sX1cA-mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check if a file is a valid image or text file\n",
        "# Attempt 1 at circumventing any data formatting issues while loading\n",
        "def is_valid_file(file_path, extension):\n",
        "    return os.path.isfile(file_path) and not os.path.basename(file_path).startswith('.') and file_path.lower().endswith(extension)"
      ],
      "metadata": {
        "id": "ZTR2jlvy78r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ensure_valid_data():\n",
        "\n",
        "  # For dirs...\n",
        "  for split in splits:\n",
        "      for sentiment in sentiments:\n",
        "\n",
        "          # Need to set paths for each pair given\n",
        "          image_modality_path = os.path.join(root_dir, split, 'image', sentiment)\n",
        "          text_modality_path = os.path.join(root_dir, split, 'text', sentiment)\n",
        "\n",
        "          # Used for debugging missing ims in early stages\n",
        "          # Checks and prints missing paths\n",
        "          # This function may be responsible for bugs in training but unsure\n",
        "          if not os.path.isdir(image_modality_path):\n",
        "              print(f\"Missing image modality directory: {image_modality_path}\")\n",
        "              continue\n",
        "          if not os.path.isdir(text_modality_path):\n",
        "              print(f\"Missing text modality directory: {text_modality_path}\")\n",
        "              continue\n",
        "\n",
        "          # Use glob to find all .jpg files\n",
        "          # glob handles all of the logic here\n",
        "          image_pattern = os.path.join(image_modality_path, '**', '*.jpg')\n",
        "          found_images = glob.glob(image_pattern, recursive=True)\n",
        "\n",
        "          for image_file in found_images:\n",
        "              # Create a text path given image\n",
        "              # Create valid path\n",
        "              relative_image_path = os.path.relpath(image_file, os.path.join(root_dir, split, 'image', sentiment))\n",
        "              text_file = os.path.join(root_dir, split, 'text', sentiment, relative_image_path)\n",
        "              text_file = os.path.splitext(text_file)[0] + '.txt'\n",
        "\n",
        "              # Check if the text file exists\n",
        "              if is_valid_file(text_file, '.txt'):\n",
        "                  image_paths.append(image_file)\n",
        "                  text_paths.append(text_file)\n",
        "                  labels.append(sentiment)\n",
        "              else:\n",
        "                  print(f\"Missing text file for image: {image_file}\")\n",
        "\n",
        "  # Creat basic df\n",
        "  data = {\n",
        "      'image_path': image_paths,\n",
        "      'text_path': text_paths,\n",
        "      'label': labels\n",
        "  }\n",
        "\n",
        "  df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "  # Save df\n",
        "  target_dir = '/content/drive/MyDrive/computer_vision_final_project/'\n",
        "  os.makedirs(target_dir, exist_ok=True)\n",
        "  if use_data_subset:\n",
        "      df_save_path = os.path.join(target_dir, 'MASAD_processed_subset.csv')\n",
        "  else:\n",
        "    df_save_path = os.path.join(target_dir, 'MASAD_processed.csv')\n",
        "  df.to_csv(df_save_path, index=False)\n",
        "  print(f\"\\nDataFrame saved at {df_save_path}\")"
      ],
      "metadata": {
        "id": "cO5alamn74Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load basic filepaths .csv"
      ],
      "metadata": {
        "id": "AS9m-yVy-oA8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80pcfVKpZu2L"
      },
      "outputs": [],
      "source": [
        "if use_data_subset:\n",
        "    df_save_path = '/content/drive/MyDrive/computer_vision_final_project/MASAD_processed_subset.csv'\n",
        "else:\n",
        "  df_save_path = '/content/drive/MyDrive/computer_vision_final_project/MASAD_processed.csv'\n",
        "\n",
        "# Load df\n",
        "df = pd.read_csv(df_save_path)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Retrieve the raw text for each row and 'raw_text' col to df."
      ],
      "metadata": {
        "id": "bKoEzEfqBRaH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYtZNi_kduWO"
      },
      "outputs": [],
      "source": [
        "tqdm.pandas()\n",
        "\n",
        "def extract_text(text_file):\n",
        "    try:\n",
        "        with open(text_file, 'r', encoding='utf-8') as file:\n",
        "            return file.read().strip()\n",
        "    except Exception as e:\n",
        "        # just return empty if not findable\n",
        "        return \"\"\n",
        "\n",
        "# Added progress bar with progress_apply because this takes forever\n",
        "if extract_text_bool:\n",
        "  print(f'value of extract text: {extract_text}')\n",
        "  df['raw_text'] = df['text_path'].progress_apply(extract_text)\n",
        "else:\n",
        "  print(f'extract text if FALSE, so reading in the pickled df from MASAD_processed_clean_text.pkl')\n",
        "  df = pd.read_pickle('/content/drive/MyDrive/computer_vision_final_project/MASAD_processed_clean_text.pkl')\n",
        "\n",
        "\n",
        "# Display the first few entries\n",
        "print(df[['text_path', 'raw_text']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27v8ngE-FD6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05504088-c416-42df-cb78-6840b7b97a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with raw text saved at /content/drive/MyDrive/computer_vision_final_project/MASAD_processed_raw_text.pkl\n"
          ]
        }
      ],
      "source": [
        "if use_data_subset:\n",
        "  save_path_raw = '/content/drive/MyDrive/computer_vision_final_project/MASAD_processed_raw_text_subset.pkl'\n",
        "else:\n",
        "  save_path_raw = '/content/drive/MyDrive/computer_vision_final_project/MASAD_processed_raw_text.pkl'\n",
        "\n",
        "# save df\n",
        "df.to_pickle(save_path_raw)\n",
        "print(f\"DataFrame with raw text saved at {save_path_raw}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3H3gljdyH-5P"
      },
      "outputs": [],
      "source": [
        "# Load the pickle file into a new df\n",
        "loaded_df = pd.read_pickle(save_path_raw)\n",
        "\n",
        "print(f\"Loaded DataFrame shape: {loaded_df.shape}\")\n",
        "print(loaded_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Clean raw text w/basic regex"
      ],
      "metadata": {
        "id": "ytT1S699Bc7Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KNXasc-d2Ee"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    # Remove all weird tags from MASAD\n",
        "    text = re.sub(r'<tag>\\S*', '', text)\n",
        "    # remove urls/links\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # replace hashtag w/space\n",
        "    text = re.sub(r'(#\\s*)+', ' ', text)\n",
        "\n",
        "    # Remove special chars and nums\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove extra whitespace\n",
        "    # Return here if buggy\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Use tqdm progress in case takes as long as extract\n",
        "df['clean_text'] = df['raw_text'].progress_apply(clean_text)\n",
        "\n",
        "# Display the first few entries\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N61WCBBXWZR"
      },
      "source": [
        "### Embedding Extraction\n",
        "Transform images, pass them into clip, extract embeddings for this step of our pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91WhPC6jAbMx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b3229b7b-6fec-4829-d9ef-6ee7720a8bdd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 200})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import CLIPImageProcessor, CLIPProcessor, CLIPImageProcessor, CLIPModel\n",
        "import numpy as np\n",
        "from transformers import CLIPImageProcessor, CLIPProcessor, CLIPTokenizerFast\n",
        "from torchvision.transforms import v2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "set_max_cell_output_height()\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "\n",
        "def processed_im_and_text(df):\n",
        "    im_list = []\n",
        "    text_list = []\n",
        "    im_paths = df['image_path'].tolist()\n",
        "    indices_to_drop = []  # To keep track of corrupted image indices\n",
        "\n",
        "    # Loop through image paths\n",
        "    for i, img_path in enumerate(tqdm(im_paths, desc=\"Loading Images\")):\n",
        "        try:\n",
        "            # Open and convert the image to RGB\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "            im_list.append(img)\n",
        "            text_list.append(df.iloc[i]['clean_text'])\n",
        "        except (UnidentifiedImageError, FileNotFoundError, OSError) as e:\n",
        "            print(f\"Warning: Skipping corrupted or unreadable image: {img_path} | Error: {e}\")\n",
        "            indices_to_drop.append(i)  # Mark this index for removal\n",
        "\n",
        "    # Ensure image and text lists have the same length\n",
        "    assert len(im_list) == len(text_list), \"Mismatch between images and texts after processing.\"\n",
        "    processed_inputs = None\n",
        "    if len(im_list) != 0:\n",
        "        processed_inputs = preprocess(text_list, im_list)\n",
        "    return processed_inputs, indices_to_drop\n",
        "\n",
        "\n",
        "def preprocess(texts, images):\n",
        "    ''' Takes in a list of text and images, returns\n",
        "    '''\n",
        "    transforms = v2.Compose([\n",
        "        v2.Resize(size=[224, 224]),\n",
        "        v2.RandomResizedCrop(size=(224, 224), antialias=True),\n",
        "        v2.RandomHorizontalFlip(p=0.2),\n",
        "        v2.RandomRotation(90),\n",
        "        v2.RandomZoomOut(p=0.3)])\n",
        "\n",
        "    transformed_images = []\n",
        "    for img in images:\n",
        "        img = transforms(img)\n",
        "        transformed_images.append(img)\n",
        "\n",
        "    ## start of text token is T_CLS, start of image token is just CLS\n",
        "    imageProcessor = CLIPImageProcessor(do_rescale=True, rescale_factor=1/255, do_normalize=True)\n",
        "    tokenizer = CLIPTokenizerFast.from_pretrained('openai/clip-vit-base-patch16', bos_token='[T_CLS]')\n",
        "\n",
        "    processor = CLIPProcessor(imageProcessor, tokenizer)\n",
        "    inputs = processor(text=texts, images=transformed_images, truncation=True, return_tensors=\"pt\", padding=True)\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data visualization functions to show original v.s. transformed images"
      ],
      "metadata": {
        "id": "5ttFyS_twyMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_a_few_images(images, labels, display_label=False):\n",
        "  # apply data augmentation to a few images\n",
        "  transforms = v2.Compose([\n",
        "    v2.Resize(size=[224, 224]),\n",
        "    v2.RandomResizedCrop(size=(224, 224), antialias=True),\n",
        "    v2.RandomHorizontalFlip(p=0.2),\n",
        "    v2.RandomRotation(90),\n",
        "    v2.RandomZoomOut(p=0.3)])\n",
        "  transformed_images = []\n",
        "  for img in images:\n",
        "      img = transforms(img)\n",
        "      transformed_images.append(img)\n",
        "\n",
        "\n",
        "  # plot each image and it's augmented version\n",
        "  fig = plt.figure(figsize=(10, 7))\n",
        "  plt.title('Sample Images and Transformations\\n')\n",
        "  plt.axis('off')\n",
        "\n",
        "  for i in range(min(3, len(images))):\n",
        "    im = images[i]\n",
        "    t_im = transformed_images[i]\n",
        "\n",
        "    plt.subplot(3, 2, 2*i+1)\n",
        "    plt.imshow(im)\n",
        "    plt.axis('off')  # Hide the axis labels\n",
        "    if display_label:\n",
        "      plt.title(f\"Image {i+1} ({labels[i][0].upper()})\") # 2*0+1=1, 2*1+1=3, 2*2+1=5\n",
        "    else:\n",
        "      plt.title(f\"Image {i+1}\") # 2*0+1=1, 2*1+1=3, 2*2+1=5\n",
        "\n",
        "    plt.subplot(3, 2, 2*i+2) # 2*0+2=2, 2*1+2=4, 2*2+2=6\n",
        "    plt.imshow(t_im)\n",
        "    plt.axis('off')  # Hide the axis labels\n",
        "    plt.title(f\"Image {i+1} with Transformation\")\n",
        "\n",
        "  root_dir = '/content/drive/MyDrive/computer_vision_final_project/'\n",
        "  plt.savefig(f'{root_dir}imgs_and_transform.png')\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "lkfIEjY080ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX4anM8yuDKk"
      },
      "outputs": [],
      "source": [
        "def extract_hidden_states(df, clip_model, batch_size=32):\n",
        "\n",
        "    all_stacked_clip_embeddings = []\n",
        "    labels = []\n",
        "    total_samples = len(df)\n",
        "    num_batches = (total_samples + batch_size - 1) // batch_size  # Ceiling division\n",
        "    total_indices_dropped = 0\n",
        "    for batch_idx in tqdm(range(num_batches), desc=\"Extracting Hidden States\"):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min(start_idx + batch_size, len(df))\n",
        "        batch_inputs, indices_to_drop = processed_im_and_text(df[start_idx:end_idx])\n",
        "\n",
        "        if indices_to_drop:\n",
        "          df = df.drop(indices_to_drop).reset_index(drop=True)\n",
        "          end_idx -= len(indices_to_drop)\n",
        "          print(f\"Dropped {len(indices_to_drop)} corrupted images. New DataFrame size: {df.shape}\")\n",
        "          total_indices_dropped += len(indices_to_drop)\n",
        "        if batch_inputs == None:\n",
        "          continue\n",
        "\n",
        "        # Slice the batch data\n",
        "        inputs = {\n",
        "            'input_ids': batch_inputs['input_ids'].to(device),\n",
        "            'attention_mask': batch_inputs['attention_mask'].to(device),\n",
        "            'pixel_values': batch_inputs['pixel_values'].to(device)\n",
        "        }\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        ## at this point, the batch inputs are the output of the clip processor\n",
        "        with torch.no_grad():\n",
        "            outputs = clip_model(**inputs)\n",
        "\n",
        "        # get embeds instead of hidden states, if changing model to work with the whole sentence/image instead of tokenized version\n",
        "        # Extract hidden states\n",
        "        text_embeddings = outputs.text_embeds\n",
        "        img_embeddings = outputs.image_embeds\n",
        "\n",
        "        valid_batch_size = end_idx - start_idx - len(indices_to_drop)\n",
        "        encoded_labels = process_labels(df.iloc[start_idx:end_idx][\"label\"].to_list())\n",
        "        labels.extend(encoded_labels)\n",
        "        combined_hidden_states = torch.stack((text_embeddings, img_embeddings), dim=1)\n",
        "\n",
        "        # Move to CPU and detach to free GPU memory\n",
        "        all_stacked_clip_embeddings.append(combined_hidden_states.cpu())\n",
        "        total_examples = sum(tensor.shape[0] for tensor in all_stacked_clip_embeddings)\n",
        "        print(f\"Processed {total_examples} examples so far.Labels size: {len(df)}\")\n",
        "\n",
        "        # Optional: Clear CUDA cache to free memory\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    torch.save(all_stacked_clip_embeddings, 'stacked_clip_embeddings_list.pt') # this is necessary in case the code breaks on torch.cat due to shape issues\n",
        "    # ^ if it does, we can just read in the embeddings without having to process them thru clip from scratch\n",
        "\n",
        "    final_labels = torch.tensor(labels, dtype=torch.float)\n",
        "    try:\n",
        "      final_hidden_states = torch.cat(all_stacked_clip_embeddings, dim=0)\n",
        "      return final_hidden_states, final_labels\n",
        "    except Exception as e:\n",
        "      print(f'ERROR: Encounterd the folowing error when trying to concatenate all the clip embeddings; \\n{e}')\n",
        "      print(f'You can debug this by using torch.load(\"stacked_clip_embeddings_list.pt\") to avoid having to re-process things w/ clip')\n",
        "\n",
        "\n",
        "def process_labels(labels):\n",
        "    \"\"\" Goes through all labels and converts from a list of strings to a pytorch tensor, 0 if negative, 1 is positive\n",
        "    \"\"\"\n",
        "    label_map = {\"negative\": 0, \"positive\": 1}  # Adjust as per your actual label names\n",
        "    encoded_labels = [label_map[label] for label in labels]\n",
        "    return torch.tensor(encoded_labels, dtype=torch.float)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcydnJrP3rxV"
      },
      "outputs": [],
      "source": [
        "def save_model(model, save_path):\n",
        "    \"\"\"\n",
        "    Saves the model's state_dict to the specified path.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained PyTorch model.\n",
        "        save_path (str): The path where the model will be saved.\n",
        "    \"\"\"\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Model weights saved to {save_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Pre-Processing Function"
      ],
      "metadata": {
        "id": "cKVh_ubzt61W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki7N8jSl7AyU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_pickle('/content/drive/MyDrive/computer_vision_final_project/MASAD_processed_clean_text.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYIzJWXZ68Ev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e4dca0-4ce7-4b9d-ed14-7528dad5089c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame size: (38066, 5)\n",
            "Scaled-down DataFrame size: (20136, 5)\n",
            "\n",
            "Class distribution in scaled-down DataFrame:\n",
            "label\n",
            "negative    10068\n",
            "positive    10068\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "target_rows_per_class = min(df['label'].value_counts())\n",
        "\n",
        "df_small = df.groupby('label').sample(n=int(target_rows_per_class/1.5), random_state=42).reset_index(drop=True)\n",
        "# Display the sizes of the original and scaled-down DataFrames\n",
        "print(f\"Original DataFrame size: {df.shape}\")\n",
        "print(f\"Scaled-down DataFrame size: {df_small.shape}\")\n",
        "# (Optional) Verify the class distribution in the scaled-down DataFrame\n",
        "print(\"\\nClass distribution in scaled-down DataFrame:\")\n",
        "print(df_small['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### initialize cuda and clip model before pre-processing the data"
      ],
      "metadata": {
        "id": "vuGme6EOwNGa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwIhyI4p32sJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339,
          "referenced_widgets": [
            "2537d3571096468c8b9e23896660c5a1",
            "256cdecb28e34dcb95e5a0f672d7330b",
            "53e4ef3346e14065ada694b4a6173db7",
            "5df256021a6b458180d68bff91903549",
            "ba5b50f1647c4477bcccccefec5675c3",
            "89492965e2054e08a80aa33adcea8062",
            "fb3f9eeb5b6b476b8976ba56c96ad74e",
            "de0879b6f38a4613b702a48e559d883f",
            "8fce334d9b8749649d857b956ce7b9bb",
            "513d5d7c65a1408d92dafa7c0a81ff8f",
            "ad3b454d924c4617b7aa93aa0318da5c",
            "7ee34ca9abd9426c9b9d765655e80050",
            "9171cc60177d46079705c255401160d3",
            "09e406636f5c47bb8e5d23bb523a54b2",
            "8844ba5af1454712ac8a8a37ee42613c",
            "f1e876af15bc4eb68e58cd5da8a57b5c",
            "e8c5971753d24a68b848d1103cf5c3c4",
            "ff5a6e5e609e4d338a186e90236eb398",
            "11a42e85faa347e384022d33dce279c9",
            "d904c5c41aab46acaf2625bb21a7392f",
            "c2d49455f23849dcb8c84a939ef3f4f1",
            "38070900ea5948d68323e5fc833fa3e8"
          ]
        },
        "outputId": "8819a224-e7c2-4b9c-871d-6048d0ba4055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model will run on cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2537d3571096468c8b9e23896660c5a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ee34ca9abd9426c9b9d765655e80050"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shapes into layer 1: 768, 512\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Projection(\n",
              "  (linear1): Linear(in_features=768, out_features=512, bias=False)\n",
              "  (linear2): Linear(in_features=512, out_features=512, bias=False)\n",
              "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (drop): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "print(f\"model will run on {device}\")\n",
        "\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "clip_model.eval()\n",
        "\n",
        "for param in clip_model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_clip_embeddings =True"
      ],
      "metadata": {
        "id": "N-R6M7n2KB2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the save directory on Google Drive\n",
        "save_dir = '/content/drive/MyDrive/computer_vision_final_project/models/'\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "# Define the save path with a descriptive filename\n",
        "embeddings_save_path = os.path.join(save_dir, 'mme_full')\n",
        "labels_save_path = os.path.join(save_dir, 'labels_full')\n",
        "\n",
        "if generate_clip_embeddings == True:\n",
        "  mme,label_encodings = extract_hidden_states(df_small, clip_model) # mme is multimodal embedding\n",
        "\n",
        "  print(f'successfully extracted the multimodal embeddings from CLIP with shape: {mme.shape}')\n",
        "  print(f'label encodings shape: {label_encodings.shape}')\n",
        "\n",
        "  # ☝🏽 modification 3:\n",
        "  # the save model function is suitable for saving a model becaue it saves the model's state dict\n",
        "  # but since our goal with the multimodal embeddings and labels is just to save them to a .pt file --\n",
        "  # since they are state-less embeddings that don't have 'state_dict's, we just use torch.save() to\n",
        "  # serialize them to a file\n",
        "  torch.save(mme, embeddings_save_path)\n",
        "  torch.save(label_encodings, labels_save_path)\n",
        "  print(f\"Embeddings saved at {embeddings_save_path}\")\n",
        "  print(f\"Labels saved at {labels_save_path}\")\n",
        "\n",
        "else:\n",
        "  print(f\"generate_clip_embeddings is {generate_clip_embeddings}, so we'll just read in the embeddings and labels from their saved .pt files: \\n{embeddings_save_path} and \\n{labels_save_path}\")\n",
        "  mme = torch.load(embeddings_save_path)\n",
        "  label_encodings = torch.load(labels_save_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "mEfHh2Hm-zoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8aebb5e-66f2-4089-a214-c3be7a0f21af",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_batches 630\n",
            "total_samples 20136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:   0%|          | 0/630 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end_idx 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:00<00:00, 117.04it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 128.98it/s]\n",
            "Extracting Hidden States:   0%|          | 1/630 [00:01<10:50,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 32 examples so far.Labels size: 20136\n",
            "end_idx 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:00<00:00, 156.12it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 143.63it/s]\n",
            "Extracting Hidden States:   0%|          | 2/630 [00:01<10:13,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 64 examples so far.Labels size: 20136\n",
            "end_idx 96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:00<00:00, 112.65it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 124.47it/s]\n",
            "Extracting Hidden States:   0%|          | 3/630 [00:02<10:00,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 96 examples so far.Labels size: 20136\n",
            "end_idx 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:00<00:00, 153.16it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 141.96it/s]\n",
            "Extracting Hidden States:   1%|          | 4/630 [00:03<09:54,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 128 examples so far.Labels size: 20136\n",
            "end_idx 160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:00<00:00, 142.09it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 128.65it/s]\n",
            "Extracting Hidden States:   1%|          | 5/630 [00:04<10:22,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 160 examples so far.Labels size: 20136\n",
            "end_idx 192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:00<00:00, 123.77it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 124.90it/s]\n",
            "Extracting Hidden States:   1%|          | 6/630 [00:06<10:55,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 192 examples so far.Labels size: 20136\n",
            "end_idx 224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:00<00:00, 115.72it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 107.84it/s]\n",
            "Extracting Hidden States:   1%|          | 7/630 [00:07<11:25,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 224 examples so far.Labels size: 20136\n",
            "end_idx 256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:00<00:00, 124.07it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 115.50it/s]\n",
            "Extracting Hidden States:   1%|▏         | 8/630 [00:08<11:20,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 256 examples so far.Labels size: 20136\n",
            "end_idx 288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:00<00:00, 148.30it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 137.46it/s]\n",
            "Extracting Hidden States:   1%|▏         | 9/630 [00:09<10:56,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 288 examples so far.Labels size: 20136\n",
            "end_idx 320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:00<00:00, 119.32it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 130.36it/s]\n",
            "Extracting Hidden States:   2%|▏         | 10/630 [00:10<10:35,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 320 examples so far.Labels size: 20136\n",
            "end_idx 352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:00<00:00, 142.97it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 144.32it/s]\n",
            "Extracting Hidden States:   2%|▏         | 11/630 [00:11<10:09,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 352 examples so far.Labels size: 20136\n",
            "end_idx 384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:00<00:00, 143.68it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 127.53it/s]\n",
            "Extracting Hidden States:   2%|▏         | 12/630 [00:12<10:08,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 384 examples so far.Labels size: 20136\n",
            "end_idx 416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:00<00:00, 133.35it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 135.62it/s]\n",
            "Extracting Hidden States:   2%|▏         | 13/630 [00:13<09:57,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 416 examples so far.Labels size: 20136\n",
            "end_idx 448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:00<00:00, 139.79it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 126.79it/s]\n",
            "Extracting Hidden States:   2%|▏         | 14/630 [00:14<09:56,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 448 examples so far.Labels size: 20136\n",
            "end_idx 480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:00<00:00, 148.42it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 140.78it/s]\n",
            "Extracting Hidden States:   2%|▏         | 15/630 [00:15<09:50,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 480 examples so far.Labels size: 20136\n",
            "end_idx 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:00<00:00, 136.00it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 131.69it/s]\n",
            "Extracting Hidden States:   3%|▎         | 16/630 [00:16<10:04,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 512 examples so far.Labels size: 20136\n",
            "end_idx 544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:00<00:00, 119.68it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 123.83it/s]\n",
            "Extracting Hidden States:   3%|▎         | 17/630 [00:17<09:59,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 544 examples so far.Labels size: 20136\n",
            "end_idx 576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:00<00:00, 144.39it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:00<00:00, 134.30it/s]\n",
            "Extracting Hidden States:   3%|▎         | 18/630 [00:17<09:58,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 576 examples so far.Labels size: 20136\n",
            "end_idx 608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:00<00:00, 94.54it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:04<00:00,  7.67it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 608 examples so far.Labels size: 20136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:   3%|▎         | 19/630 [00:22<22:05,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end_idx 640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:23,  1.34it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:26,  1.12it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.07it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:27,  1.04it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.04it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.12it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:07<00:31,  1.27s/it]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:08<00:28,  1.17s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:09<00:25,  1.11s/it]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:10<00:23,  1.05s/it]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:11<00:22,  1.05s/it]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:12<00:20,  1.01s/it]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:13<00:19,  1.00s/it]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:14<00:18,  1.02s/it]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:15<00:16,  1.01it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:16<00:15,  1.03it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:17<00:14,  1.03it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:18<00:13,  1.03it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:19<00:12,  1.04it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:20<00:11,  1.04it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:10,  1.05it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:22<00:09,  1.00it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:23<00:08,  1.02it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:24<00:09,  1.15s/it]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:25<00:07,  1.10s/it]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:26<00:06,  1.05s/it]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:27<00:05,  1.02s/it]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:28<00:03,  1.01it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:29<00:02,  1.02it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:32<00:03,  1.68s/it]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:33<00:01,  1.46s/it]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n",
            "Extracting Hidden States:   3%|▎         | 20/630 [00:58<2:04:12, 12.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 640 examples so far.Labels size: 20136\n",
            "end_idx 672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:31,  1.02s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.05it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:28,  1.01it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:27,  1.02it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:26,  1.03it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:26,  1.01s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:24,  1.02it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:23,  1.02it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:09<00:25,  1.10s/it]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:10<00:23,  1.06s/it]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:11<00:22,  1.05s/it]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:12<00:20,  1.04s/it]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:13<00:18,  1.01it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:14<00:18,  1.03s/it]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:15<00:17,  1.04s/it]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:17<00:20,  1.27s/it]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:17<00:17,  1.16s/it]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:18<00:15,  1.09s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:19<00:13,  1.03s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:20<00:12,  1.03s/it]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:22<00:11,  1.07s/it]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:23<00:10,  1.08s/it]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:24<00:09,  1.04s/it]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:24<00:07,  1.01it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:25<00:07,  1.01s/it]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:27<00:06,  1.03s/it]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:27<00:05,  1.00s/it]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:29<00:04,  1.01s/it]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:29<00:02,  1.01it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:30<00:01,  1.03it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:31<00:00,  1.03it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:32<00:00,  1.03s/it]\n",
            "Extracting Hidden States:   3%|▎         | 21/630 [01:32<3:09:00, 18.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 672 examples so far.Labels size: 20136\n",
            "end_idx 704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:27,  1.14it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:44,  1.49s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:03<00:35,  1.23s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:04<00:30,  1.10s/it]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:05<00:27,  1.01s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:06<00:29,  1.14s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:07<00:27,  1.11s/it]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:08<00:25,  1.05s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:11<00:33,  1.46s/it]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:12<00:28,  1.30s/it]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:13<00:25,  1.19s/it]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:14<00:23,  1.16s/it]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:15<00:20,  1.10s/it]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:16<00:19,  1.07s/it]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:17<00:17,  1.03s/it]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:18<00:16,  1.01s/it]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:19<00:14,  1.01it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:20<00:13,  1.00it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:20<00:12,  1.03it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:21<00:11,  1.01it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:22<00:10,  1.01it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:24<00:10,  1.02s/it]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:24<00:08,  1.01it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:25<00:07,  1.06it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:26<00:06,  1.03it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:27<00:05,  1.04it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:28<00:04,  1.04it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:29<00:03,  1.14it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:30<00:02,  1.10it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:31<00:01,  1.11it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:32<00:00,  1.09it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:33<00:00,  1.04s/it]\n",
            "Extracting Hidden States:   3%|▎         | 22/630 [02:06<3:55:14, 23.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 704 examples so far.Labels size: 20136\n",
            "end_idx 736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:33,  1.08s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:03<00:48,  1.61s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:03<00:35,  1.21s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:04<00:32,  1.15s/it]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:05<00:28,  1.04s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:06<00:25,  1.00it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:07<00:25,  1.01s/it]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:08<00:24,  1.02s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:09<00:22,  1.01it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:10<00:20,  1.06it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:11<00:20,  1.03it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:12<00:19,  1.02it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:13<00:18,  1.02it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:14<00:17,  1.04it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:15<00:16,  1.04it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:16<00:15,  1.03it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:17<00:14,  1.02it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:18<00:13,  1.02it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:19<00:12,  1.04it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:20<00:11,  1.07it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:21<00:10,  1.06it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:22<00:09,  1.05it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:23<00:08,  1.03it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:24<00:07,  1.03it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:24<00:06,  1.04it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:25<00:05,  1.09it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:26<00:04,  1.08it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:27<00:03,  1.05it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:28<00:02,  1.06it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:29<00:01,  1.02it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:30<00:00,  1.01it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:31<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 736 examples so far.Labels size: 20136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:   4%|▎         | 23/630 [02:38<4:23:01, 26.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end_idx 768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:28,  1.10it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:24,  1.20it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.08it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:25,  1.08it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:28,  1.04s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:26,  1.01s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:24,  1.01it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:24,  1.00s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.03it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.03it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.05it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.07it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:18,  1.05it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.04it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:16,  1.05it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:17,  1.11s/it]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:16,  1.07s/it]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:14,  1.05s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:13,  1.02s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:12,  1.03s/it]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:10,  1.01it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:10,  1.01s/it]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:08,  1.09it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:07,  1.05it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:24<00:06,  1.05it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:25<00:05,  1.05it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:26<00:04,  1.05it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:27<00:03,  1.08it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:28<00:02,  1.07it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:29<00:01,  1.08it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:30<00:00,  1.07it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:31<00:00,  1.03it/s]\n",
            "Extracting Hidden States:   4%|▍         | 24/630 [03:10<4:40:12, 27.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 768 examples so far.Labels size: 20136\n",
            "end_idx 800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:29,  1.07it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:30,  1.02s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:28,  1.03it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:24,  1.12it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.10it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.04it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.05it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.07it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.03it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.04it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:20,  1.04it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:19,  1.01it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:18,  1.04it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.07it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.09it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:14,  1.07it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:14,  1.04it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:13,  1.03it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:12,  1.03it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:11,  1.04it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:10,  1.04it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:09,  1.04it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.04it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.05it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.05it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.04it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.04it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:04,  1.02s/it]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.03it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.04it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.06it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n",
            "Extracting Hidden States:   4%|▍         | 25/630 [03:41<4:50:25, 28.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 800 examples so far.Labels size: 20136\n",
            "end_idx 832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:27,  1.11it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.07it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.05it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:27,  1.04it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:05<00:34,  1.28s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:06<00:33,  1.29s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:08<00:31,  1.26s/it]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:09<00:28,  1.18s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:10<00:25,  1.10s/it]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:11<00:23,  1.07s/it]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:12<00:21,  1.04s/it]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:13<00:20,  1.02s/it]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:14<00:20,  1.06s/it]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:15<00:18,  1.02s/it]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:15<00:16,  1.03it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:16<00:15,  1.03it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:17<00:14,  1.00it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:18<00:13,  1.01it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:19<00:12,  1.04it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:20<00:11,  1.03it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:21<00:10,  1.01it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:22<00:09,  1.01it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:23<00:08,  1.04it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:24<00:07,  1.08it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:25<00:06,  1.03it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:26<00:05,  1.04it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:27<00:04,  1.04it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:28<00:03,  1.05it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:29<00:02,  1.06it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:30<00:01,  1.00it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:31<00:00,  1.01it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:32<00:00,  1.01s/it]\n",
            "Extracting Hidden States:   4%|▍         | 26/630 [04:14<5:03:42, 30.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 832 examples so far.Labels size: 20136\n",
            "end_idx 864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:26,  1.17it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:29,  1.02it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:28,  1.01it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:27,  1.03it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:26,  1.03it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:25,  1.04it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:24,  1.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping corrupted or unreadable image: /content/drive/MyDrive/MASAD/train/image/negative/night/8931800994.jpg | Error: cannot identify image file '/content/drive/.shortcut-targets-by-id/1p7VIrw0VHGx8AwJZDUlVS99LZMom5-0J/MASAD/train/image/negative/night/8931800994.jpg'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.09it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.07it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:10<00:26,  1.22s/it]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:11<00:23,  1.12s/it]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:12<00:21,  1.07s/it]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:13<00:19,  1.02s/it]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:14<00:18,  1.00s/it]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:15<00:16,  1.00it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:15,  1.04it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:14,  1.04it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:13,  1.06it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:12,  1.06it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:11,  1.05it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:10,  1.05it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:08,  1.16it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:07,  1.14it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:07,  1.08it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:24<00:06,  1.07it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:25<00:05,  1.11it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.21it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.21it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.18it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.21it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.22it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped 1 corrupted images. New DataFrame size: (20135, 5)\n",
            "clip_error False\n",
            "text embeddings have shape: torch.Size([31, 512]) and img embeddings have shape: torch.Size([31, 512])\n",
            "combined hidden states now has shape: torch.Size([31, 2, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:   4%|▍         | 27/630 [04:45<5:05:17, 30.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 863 examples so far.Labels size: 20135\n",
            "end_idx 896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:26,  1.16it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.07it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.08it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.08it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:05<00:37,  1.37s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:06<00:32,  1.26s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:07<00:26,  1.07s/it]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:08<00:24,  1.01s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:09<00:22,  1.01it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:10<00:20,  1.07it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:11<00:21,  1.05s/it]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:12<00:20,  1.04s/it]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:13<00:19,  1.01s/it]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:14<00:17,  1.03it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:15<00:15,  1.06it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:16<00:15,  1.06it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:17<00:14,  1.06it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:18<00:13,  1.06it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:19<00:12,  1.06it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:20<00:14,  1.21s/it]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:21<00:12,  1.14s/it]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:22<00:10,  1.09s/it]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:23<00:09,  1.05s/it]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:24<00:08,  1.01s/it]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:25<00:06,  1.02it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:26<00:05,  1.12it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:27<00:04,  1.12it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:28<00:03,  1.08it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:29<00:02,  1.06it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:29<00:01,  1.11it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:30<00:00,  1.12it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n",
            "Extracting Hidden States:   4%|▍         | 28/630 [05:18<5:12:09, 31.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 895 examples so far.Labels size: 20135\n",
            "end_idx 928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:28,  1.10it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.04it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.07it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:25,  1.12it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:05<00:31,  1.17s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:06<00:28,  1.09s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:07<00:26,  1.05s/it]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:08<00:24,  1.00s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.05it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.05it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:20,  1.04it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:19,  1.02it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.10it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.11it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.08it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:14,  1.07it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:14,  1.07it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:12,  1.08it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:12,  1.05it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:11,  1.06it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:10,  1.06it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:09,  1.05it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:08,  1.05it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:07,  1.04it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.08it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.06it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:28<00:08,  1.61s/it]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:29<00:05,  1.42s/it]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:29<00:03,  1.22s/it]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:30<00:02,  1.19s/it]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:31<00:01,  1.11s/it]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:32<00:00,  1.03s/it]\n",
            "Extracting Hidden States:   5%|▍         | 29/630 [05:52<5:19:10, 31.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 927 examples so far.Labels size: 20135\n",
            "end_idx 960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:29,  1.05it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:25,  1.20it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.11it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:23,  1.17it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:23,  1.17it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.10it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.13it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.12it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:07<00:20,  1.12it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.06it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:21,  1.03s/it]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:20,  1.00s/it]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:18,  1.04it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.05it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:16,  1.05it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.07it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.08it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:13,  1.06it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.05it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:10,  1.13it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.10it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.07it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.10it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.09it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.13it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.09it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.10it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.08it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.11it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.10it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.10it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 959 examples so far.Labels size: 20135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:   5%|▍         | 30/630 [06:22<5:14:06, 31.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end_idx 992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:29,  1.07it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:27,  1.08it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.08it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:25,  1.09it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:23,  1.13it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:21,  1.19it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:21,  1.19it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.13it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:07<00:20,  1.15it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:08<00:20,  1.09it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:09<00:19,  1.06it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:18,  1.07it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:17,  1.10it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.07it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:14,  1.16it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.12it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.10it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.10it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:11,  1.10it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:17<00:10,  1.17it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:18<00:09,  1.16it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:19<00:09,  1.03it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:20<00:08,  1.06it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:21<00:07,  1.06it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:22<00:06,  1.04it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.06it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.13it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.16it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.11it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.11it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.04it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:28<00:00,  1.11it/s]\n",
            "Extracting Hidden States:   5%|▍         | 31/630 [06:52<5:08:23, 30.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 991 examples so far.Labels size: 20135\n",
            "end_idx 1024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:26,  1.19it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:26,  1.11it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.11it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.04it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.08it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.11it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.09it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.07it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.01it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.04it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:20,  1.05it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.06it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:18,  1.02it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.04it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:16,  1.04it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:15,  1.07it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:14,  1.06it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:13,  1.07it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.08it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.07it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.03it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.07it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.11it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.09it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.11it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.09it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.06it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.06it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.17it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.14it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.15it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.09it/s]\n",
            "Extracting Hidden States:   5%|▌         | 32/630 [07:22<5:06:33, 30.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1023 examples so far.Labels size: 20135\n",
            "end_idx 1056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:28,  1.08it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:27,  1.07it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:03<00:31,  1.07s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:04<00:29,  1.04s/it]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:05<00:26,  1.00it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:25,  1.01it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.10it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:20,  1.19it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:19,  1.18it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:19,  1.15it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:18,  1.14it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.09it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:18,  1.03it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.02it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:17,  1.02s/it]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:16,  1.00s/it]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:14,  1.00it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:14,  1.01s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:12,  1.03it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:11,  1.02it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:10,  1.03it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:09,  1.03it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:08,  1.02it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:07,  1.02it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.05it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.07it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.06it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.10it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.09it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.12it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.13it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
            "Extracting Hidden States:   5%|▌         | 33/630 [07:53<5:06:48, 30.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1055 examples so far.Labels size: 20135\n",
            "end_idx 1088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:28,  1.10it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.04it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:03<00:30,  1.04s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:27,  1.01it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:26,  1.03it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:25,  1.04it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.04it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.05it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:19,  1.16it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.09it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.06it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.10it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.10it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.09it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.12it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.08it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.08it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:13,  1.06it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.07it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.06it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.03it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.07it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.04it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.10it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.10it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.13it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.15it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.13it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.11it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:02,  1.04s/it]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:01,  1.02s/it]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
            "Extracting Hidden States:   5%|▌         | 34/630 [08:24<5:07:09, 30.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1087 examples so far.Labels size: 20135\n",
            "end_idx 1120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:39,  1.26s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:32,  1.07s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:03<00:29,  1.03s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:04<00:28,  1.04s/it]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:05<00:27,  1.00s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:06<00:25,  1.01it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:07<00:24,  1.02it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.07it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:20,  1.10it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:18,  1.17it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:18,  1.14it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:17,  1.15it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.11it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.09it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.08it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:14,  1.10it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.09it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:13,  1.05it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:13,  1.04s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:12,  1.01s/it]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:10,  1.00it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:09,  1.02it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:08,  1.04it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.04it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.05it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.10it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.10it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.08it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.07it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.06it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.07it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
            "Extracting Hidden States:   6%|▌         | 35/630 [08:55<5:07:03, 30.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1119 examples so far.Labels size: 20135\n",
            "end_idx 1152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:27,  1.14it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:22,  1.32it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:24,  1.19it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:24,  1.13it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:26,  1.02it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.07it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.10it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.07it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.07it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.08it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:09<00:19,  1.10it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:19,  1.04it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:17,  1.07it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.08it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:16,  1.05it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:15,  1.06it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:14,  1.04it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:13,  1.07it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.04it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.00it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.03it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.04it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.05it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.06it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.03it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.01it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.03it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.05it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.04it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.05it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.05it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.07it/s]\n",
            "Extracting Hidden States:   6%|▌         | 36/630 [09:26<5:06:19, 30.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1151 examples so far.Labels size: 20135\n",
            "end_idx 1184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:30,  1.02it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.05it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:25,  1.12it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:25,  1.10it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.09it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.07it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:24,  1.03it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.12it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.09it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:19,  1.12it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:18,  1.11it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:17,  1.13it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:18,  1.06it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.08it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:16<00:30,  1.77s/it]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:17<00:24,  1.51s/it]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:18<00:19,  1.28s/it]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:19<00:16,  1.18s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:20<00:14,  1.11s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:21<00:12,  1.05s/it]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:21<00:11,  1.01s/it]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:22<00:09,  1.01it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:23<00:08,  1.03it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:24<00:07,  1.06it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:25<00:06,  1.07it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:26<00:05,  1.06it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:27<00:04,  1.06it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:29<00:04,  1.11s/it]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:29<00:03,  1.05s/it]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:30<00:02,  1.01s/it]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:31<00:00,  1.03it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:34<00:00,  1.07s/it]\n",
            "Extracting Hidden States:   6%|▌         | 37/630 [10:01<5:17:28, 32.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1183 examples so far.Labels size: 20135\n",
            "end_idx 1216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:26,  1.19it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:27,  1.08it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:25,  1.13it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:27,  1.03it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.04it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:25,  1.02it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:24,  1.03it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.08it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.09it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.08it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:18,  1.12it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:17,  1.11it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:17,  1.11it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.12it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.11it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.10it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:15,  1.06s/it]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:13,  1.00it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.03it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.03it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.10it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.10it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:07,  1.13it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.05it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.06it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.10it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.10it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:04,  1.00s/it]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.02it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.07it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.09it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.07it/s]\n",
            "Extracting Hidden States:   6%|▌         | 38/630 [10:32<5:12:27, 31.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1215 examples so far.Labels size: 20135\n",
            "end_idx 1248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:29,  1.06it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.06it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:25,  1.12it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:25,  1.08it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.11it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.12it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.09it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.05it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.04it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.05it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:11<00:25,  1.21s/it]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:22,  1.10s/it]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:19,  1.03s/it]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.02it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:16,  1.03it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:15,  1.04it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:13,  1.08it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:13,  1.07it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:12,  1.06it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:11,  1.01it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:10,  1.03it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:09,  1.02it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:08,  1.07it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:07,  1.04it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:24<00:06,  1.08it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:25<00:05,  1.08it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.07it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:27<00:04,  1.01s/it]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:28<00:02,  1.01it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.12it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.10it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
            "Extracting Hidden States:   6%|▌         | 39/630 [11:03<5:11:47, 31.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1247 examples so far.Labels size: 20135\n",
            "end_idx 1280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:33,  1.08s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:32,  1.08s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:03<00:29,  1.02s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:04<00:28,  1.02s/it]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:05<00:26,  1.02it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.07it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.09it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.09it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.07it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.07it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:20,  1.05it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:17,  1.12it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.10it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.08it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.08it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:15,  1.07it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:14,  1.02it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:14,  1.01s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:12,  1.02it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:11,  1.06it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.09it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:08,  1.13it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.04it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.06it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.06it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.05it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.04it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.02it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.00it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.03it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.02it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n",
            "Extracting Hidden States:   6%|▋         | 40/630 [11:35<5:10:29, 31.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1279 examples so far.Labels size: 20135\n",
            "end_idx 1312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:27,  1.13it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:27,  1.09it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.06it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:27,  1.01it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:26,  1.01it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:25,  1.03it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.05it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.05it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.06it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.08it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.07it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.08it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.10it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.07it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.08it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.12it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:16,  1.07s/it]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:13,  1.02it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:12,  1.04it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.08it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.04it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.05it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.04it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.03it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.04it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.02it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.02it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.05it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.09it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.21it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.24it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.07it/s]\n",
            "Extracting Hidden States:   7%|▋         | 41/630 [12:05<5:07:03, 31.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1311 examples so far.Labels size: 20135\n",
            "end_idx 1344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:28,  1.07it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:32,  1.08s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:03<00:30,  1.04s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:27,  1.02it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.07it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.07it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:24,  1.03it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.06it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.06it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.08it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.05it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.07it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.08it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.09it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.07it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:14,  1.10it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.10it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:15,  1.12s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:13,  1.06s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:12,  1.01s/it]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:10,  1.00it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:09,  1.05it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:08,  1.05it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:08,  1.01s/it]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:24<00:06,  1.03it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:25<00:05,  1.08it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.08it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.10it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.09it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.08it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.10it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n",
            "Extracting Hidden States:   7%|▋         | 42/630 [12:37<5:06:27, 31.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1343 examples so far.Labels size: 20135\n",
            "end_idx 1376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:30,  1.03it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.06it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.07it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:25,  1.11it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.09it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.04it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:24,  1.03it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:23,  1.01it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.03it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.03it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.06it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.08it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.09it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:15,  1.18it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.07it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.10it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.11it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.09it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.06it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.09it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.09it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.04it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.06it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.07it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:24<00:08,  1.23s/it]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:25<00:06,  1.14s/it]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:26<00:05,  1.06s/it]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.01it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.03it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.08it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.02it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
            "Extracting Hidden States:   7%|▋         | 43/630 [13:08<5:06:46, 31.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1375 examples so far.Labels size: 20135\n",
            "end_idx 1408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:21,  1.43it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:24,  1.23it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:24,  1.17it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:22,  1.27it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:23,  1.17it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:22,  1.14it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:05<00:20,  1.20it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:06<00:20,  1.16it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:07<00:20,  1.12it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:08<00:20,  1.10it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:09<00:19,  1.10it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:18,  1.09it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:17,  1.09it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.09it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.08it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.11it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.10it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:15<00:12,  1.09it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:16<00:11,  1.11it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:17<00:10,  1.11it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:18<00:09,  1.11it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:19<00:09,  1.10it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:20<00:08,  1.09it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:21<00:06,  1.17it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:22<00:06,  1.14it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:22<00:05,  1.16it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:23<00:04,  1.15it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:24<00:03,  1.09it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:25<00:02,  1.07it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:26<00:01,  1.05it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:27<00:00,  1.06it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:28<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1407 examples so far.Labels size: 20135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:   7%|▋         | 44/630 [13:38<5:00:56, 30.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end_idx 1440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:44,  1.42s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:03<00:58,  1.94s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:04<00:41,  1.43s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:06<00:42,  1.52s/it]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:07<00:34,  1.27s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:07<00:29,  1.14s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:08<00:26,  1.05s/it]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:09<00:25,  1.04s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:10<00:23,  1.02s/it]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:11<00:21,  1.01it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:12<00:20,  1.02it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:14<00:22,  1.14s/it]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:14<00:19,  1.04s/it]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:16<00:19,  1.10s/it]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:16<00:16,  1.03it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:17<00:14,  1.08it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:18<00:14,  1.04it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:19<00:13,  1.07it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:20<00:12,  1.07it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:21<00:11,  1.03it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:22<00:10,  1.05it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:23<00:09,  1.01it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:24<00:08,  1.02it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:25<00:07,  1.06it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:26<00:06,  1.05it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:27<00:05,  1.07it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:28<00:04,  1.05it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:29<00:03,  1.08it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:29<00:02,  1.20it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:30<00:01,  1.18it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:31<00:00,  1.16it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:32<00:00,  1.02s/it]\n",
            "Extracting Hidden States:   7%|▋         | 45/630 [14:11<5:08:20, 31.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1439 examples so far.Labels size: 20135\n",
            "end_idx 1472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:30,  1.03s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.06it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:04<00:27,  1.01it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:26,  1.04it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.09it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.07it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:23,  1.03it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.08it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.07it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:18,  1.11it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.08it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:13<00:24,  1.29s/it]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:14<00:21,  1.18s/it]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:15<00:18,  1.07s/it]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:16<00:16,  1.00s/it]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:14,  1.05it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:13,  1.07it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:11,  1.09it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:11,  1.01it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:11,  1.00s/it]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:09,  1.01it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:08,  1.02it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:07,  1.03it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:24<00:06,  1.04it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:25<00:05,  1.06it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:26<00:04,  1.04it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:27<00:03,  1.03it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:28<00:02,  1.08it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:29<00:01,  1.06it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:30<00:00,  1.10it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:31<00:00,  1.03it/s]\n",
            "Extracting Hidden States:   7%|▋         | 46/630 [14:43<5:08:23, 31.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1471 examples so far.Labels size: 20135\n",
            "end_idx 1504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:28,  1.08it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.05it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:28,  1.03it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:27,  1.03it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.08it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.09it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:24,  1.02it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:23,  1.04it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.01it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.05it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:20,  1.05it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:19,  1.02it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.06it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.07it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.06it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:15,  1.06it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:14,  1.07it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:16,  1.17s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:14,  1.12s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:12,  1.03s/it]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:11,  1.01s/it]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:09,  1.03it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:08,  1.02it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:07,  1.03it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:24<00:06,  1.09it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:25<00:05,  1.12it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:26<00:04,  1.03it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:27<00:03,  1.06it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.13it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.15it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.13it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n",
            "Extracting Hidden States:   7%|▋         | 47/630 [15:15<5:07:17, 31.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1503 examples so far.Labels size: 20135\n",
            "end_idx 1536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:26,  1.17it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:25,  1.19it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.08it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.07it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.07it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.07it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.11it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.06it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.06it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.06it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.10it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:19,  1.05it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:19,  1.05s/it]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:18,  1.05s/it]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:17,  1.00s/it]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:15,  1.03it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:15,  1.06s/it]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:14,  1.03s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:13,  1.01s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:11,  1.00it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:10,  1.08it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:09,  1.10it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:07,  1.16it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.11it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.11it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.11it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.16it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.05it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.08it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.10it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.10it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1535 examples so far.Labels size: 20135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:   8%|▊         | 48/630 [15:45<5:04:30, 31.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end_idx 1568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:22,  1.36it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:24,  1.23it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:23,  1.22it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:24,  1.13it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:26,  1.03it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:25,  1.03it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.05it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.05it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.05it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.08it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.06it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.07it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.07it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.06it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.08it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:15,  1.06it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:15,  1.01s/it]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:13,  1.03it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.04it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.09it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.09it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.08it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.09it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.09it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.11it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:06,  1.06s/it]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:05,  1.03s/it]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.01it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.04it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.07it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.07it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
            "Extracting Hidden States:   8%|▊         | 49/630 [16:17<5:03:20, 31.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1567 examples so far.Labels size: 20135\n",
            "end_idx 1600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:30,  1.02it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.05it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.07it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:27,  1.03it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:05<00:28,  1.06s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:26,  1.02s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:07<00:27,  1.10s/it]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:08<00:24,  1.01s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.02it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.07it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:18,  1.11it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:12<00:20,  1.04s/it]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:19,  1.02s/it]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:14<00:21,  1.22s/it]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:15<00:19,  1.13s/it]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:16<00:17,  1.08s/it]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:17<00:15,  1.05s/it]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:18<00:14,  1.04s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:19<00:13,  1.02s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:20<00:11,  1.07it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:21<00:10,  1.08it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:22<00:09,  1.04it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:23<00:08,  1.06it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:24<00:07,  1.06it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:25<00:07,  1.02s/it]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:26<00:05,  1.01it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:27<00:04,  1.03it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:27<00:03,  1.06it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:29<00:02,  1.02it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:29<00:01,  1.04it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:30<00:00,  1.04it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:31<00:00,  1.01it/s]\n",
            "Extracting Hidden States:   8%|▊         | 50/630 [16:49<5:06:27, 31.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1599 examples so far.Labels size: 20135\n",
            "end_idx 1632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:30,  1.02it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:27,  1.11it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:05<01:00,  2.07s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:06<00:45,  1.61s/it]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:07<00:36,  1.36s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:08<00:32,  1.26s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:09<00:28,  1.12s/it]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:09<00:25,  1.06s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:10<00:22,  1.00it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:12<00:26,  1.19s/it]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:13<00:23,  1.12s/it]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:14<00:21,  1.06s/it]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:15<00:19,  1.03s/it]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:17<00:23,  1.32s/it]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:18<00:20,  1.22s/it]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:19<00:18,  1.15s/it]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:20<00:16,  1.07s/it]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:21<00:14,  1.03s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:22<00:13,  1.03s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:22<00:11,  1.02it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:23<00:10,  1.03it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:24<00:09,  1.03it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:25<00:08,  1.03it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:26<00:07,  1.05it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:27<00:06,  1.05it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:28<00:05,  1.04it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:29<00:04,  1.12it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:30<00:03,  1.14it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:31<00:02,  1.09it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:32<00:01,  1.10it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:33<00:00,  1.10it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:34<00:00,  1.06s/it]\n",
            "Extracting Hidden States:   8%|▊         | 51/630 [17:24<5:14:51, 32.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1631 examples so far.Labels size: 20135\n",
            "end_idx 1664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:28,  1.11it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:29,  1.03it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:28,  1.01it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:27,  1.03it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:26,  1.01it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:25,  1.04it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:24,  1.02it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:23,  1.00it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.02it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.05it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.07it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.08it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.08it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.08it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.08it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:14,  1.11it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.13it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.13it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:10,  1.19it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:12,  1.05s/it]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:11,  1.03s/it]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:10,  1.02s/it]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:09,  1.01s/it]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:07,  1.01it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.06it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.10it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.09it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.09it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.09it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.08it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.05it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n",
            "Extracting Hidden States:   8%|▊         | 52/630 [17:55<5:10:38, 32.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1663 examples so far.Labels size: 20135\n",
            "end_idx 1696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:29,  1.05it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:26,  1.14it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:25,  1.13it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:24,  1.16it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.09it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.06it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.13it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.11it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:07<00:18,  1.22it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:08<00:18,  1.20it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:09<00:18,  1.16it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:17,  1.13it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:17,  1.10it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.09it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.09it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.08it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:14,  1.04it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:13,  1.05it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.07it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:17<00:10,  1.14it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:18<00:09,  1.10it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:19<00:08,  1.12it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:20<00:07,  1.14it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:21<00:07,  1.09it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:22<00:06,  1.04it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.06it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.10it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.11it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.14it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:26<00:01,  1.21it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:27<00:00,  1.14it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:28<00:00,  1.11it/s]\n",
            "Extracting Hidden States:   8%|▊         | 53/630 [18:25<5:02:18, 31.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1695 examples so far.Labels size: 20135\n",
            "end_idx 1728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:28,  1.07it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:31,  1.05s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:28,  1.01it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.05it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.09it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.12it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:24,  1.01it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:23,  1.02it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.02it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.05it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.06it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:19,  1.05it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:18,  1.04it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.04it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:16,  1.04it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:15,  1.04it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:14,  1.04it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:15,  1.11s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:13,  1.05s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:12,  1.02s/it]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:11,  1.04s/it]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:10,  1.03s/it]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:08,  1.02it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:07,  1.04it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:24<00:06,  1.09it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:25<00:05,  1.10it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:26<00:04,  1.08it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:27<00:03,  1.07it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:28<00:02,  1.09it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.10it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.09it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
            "Extracting Hidden States:   9%|▊         | 54/630 [18:57<5:02:44, 31.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1727 examples so far.Labels size: 20135\n",
            "end_idx 1760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:34,  1.13s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:31,  1.04s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:03<00:29,  1.00s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:27,  1.03it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.05it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.05it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.05it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.08it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.07it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:19,  1.10it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.10it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:17,  1.12it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.08it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.08it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.07it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:15,  1.06it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.07it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:14,  1.00s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.06it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.06it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.07it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.07it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:07,  1.18it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.13it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.11it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.14it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.07it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.06it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.06it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.09it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.09it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.07it/s]\n",
            "Extracting Hidden States:   9%|▊         | 55/630 [19:27<4:59:27, 31.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1759 examples so far.Labels size: 20135\n",
            "end_idx 1792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:28,  1.09it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:29,  1.02it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.10it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:24,  1.13it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:27,  1.01s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:06<00:32,  1.23s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:07<00:28,  1.15s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping corrupted or unreadable image: /content/drive/MyDrive/MASAD/train/image/negative/bird/3833393977.jpg | Error: cannot identify image file '/content/drive/.shortcut-targets-by-id/1p7VIrw0VHGx8AwJZDUlVS99LZMom5-0J/MASAD/train/image/negative/bird/3833393977.jpg'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:  25%|██▌       | 8/32 [00:08<00:26,  1.09s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:09<00:23,  1.04s/it]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:10<00:20,  1.07it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:11<00:20,  1.04it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:12<00:18,  1.06it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.06it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.10it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.13it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:14,  1.10it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:17<00:16,  1.11s/it]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:18<00:14,  1.04s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:12,  1.07it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:12,  1.02s/it]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:21<00:13,  1.24s/it]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:22<00:11,  1.17s/it]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:23<00:09,  1.06s/it]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:24<00:07,  1.00it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:25<00:07,  1.01s/it]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:26<00:05,  1.07it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:27<00:04,  1.04it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:28<00:03,  1.03it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:29<00:02,  1.02it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:30<00:01,  1.03it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:33<00:01,  1.67s/it]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped 1 corrupted images. New DataFrame size: (20134, 5)\n",
            "clip_error False\n",
            "text embeddings have shape: torch.Size([31, 512]) and img embeddings have shape: torch.Size([31, 512])\n",
            "combined hidden states now has shape: torch.Size([31, 2, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:   9%|▉         | 56/630 [20:03<5:10:27, 32.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1790 examples so far.Labels size: 20134\n",
            "end_idx 1824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:32,  1.03s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:03<00:50,  1.67s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:04<00:39,  1.36s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:05<00:35,  1.28s/it]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:06<00:31,  1.17s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:07<00:27,  1.07s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:07<00:23,  1.04it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:08<00:22,  1.06it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:09<00:22,  1.03it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:10<00:21,  1.01it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:11<00:20,  1.05it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:12<00:18,  1.05it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:13<00:17,  1.08it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:14<00:16,  1.12it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:15<00:15,  1.12it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:13,  1.19it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:12,  1.18it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:12,  1.10it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:11,  1.10it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:10,  1.09it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:09,  1.12it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:08,  1.11it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:08,  1.09it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:07,  1.07it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:24<00:06,  1.09it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:25<00:05,  1.09it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.18it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.19it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.16it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.14it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.11it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1822 examples so far.Labels size: 20134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:   9%|▉         | 57/630 [20:34<5:06:21, 32.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end_idx 1856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:29,  1.05it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.05it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.04it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.06it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.05it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.06it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.05it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.09it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.08it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.08it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.08it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.08it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.06it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.05it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.07it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.08it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.09it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.11it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:11,  1.13it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:10,  1.16it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:09,  1.15it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:19<00:08,  1.24it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:20<00:07,  1.16it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:21<00:07,  1.13it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:22<00:06,  1.08it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.07it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.10it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.11it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.12it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:02,  1.05s/it]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:01,  1.02s/it]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.08it/s]\n",
            "Extracting Hidden States:   9%|▉         | 58/630 [21:04<5:01:02, 31.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1854 examples so far.Labels size: 20134\n",
            "end_idx 1888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:31,  1.02s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:29,  1.03it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:28,  1.03it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.05it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.07it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.08it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.07it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.11it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:20,  1.15it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:19,  1.13it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:09<00:18,  1.15it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:17,  1.16it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:16,  1.18it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:15,  1.16it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:14,  1.14it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:13,  1.20it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.14it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.16it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:16<00:11,  1.14it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:17<00:10,  1.13it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:18<00:08,  1.23it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:19<00:08,  1.17it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:20<00:07,  1.16it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:21<00:07,  1.13it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:22<00:06,  1.10it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.10it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.10it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:24<00:03,  1.10it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:25<00:02,  1.06it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:26<00:01,  1.09it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:27<00:00,  1.12it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:28<00:00,  1.12it/s]\n",
            "Extracting Hidden States:   9%|▉         | 59/630 [21:34<4:54:11, 30.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1886 examples so far.Labels size: 20134\n",
            "end_idx 1920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:30,  1.03it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:30,  1.03s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:28,  1.02it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.04it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.10it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.05it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.05it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.05it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.05it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:19,  1.15it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:18,  1.12it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.10it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:16,  1.12it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.10it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.10it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.10it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:14,  1.05it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:13,  1.04it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.06it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.09it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.08it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.05it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.08it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.07it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.06it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.10it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.14it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.11it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.09it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.13it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.10it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1918 examples so far.Labels size: 20134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:  10%|▉         | 60/630 [22:04<4:52:19, 30.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end_idx 1952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:30,  1.03it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:36,  1.20s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:03<00:27,  1.04it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.04it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.05it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.08it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.06it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.09it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.06it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:18,  1.18it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:18,  1.11it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:17,  1.12it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:16,  1.14it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:15,  1.15it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.12it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:18,  1.13s/it]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:16,  1.10s/it]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:14,  1.06s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:13,  1.02s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:12,  1.02s/it]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:10,  1.00it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:10,  1.03s/it]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:08,  1.03it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:07,  1.03it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:24<00:06,  1.06it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:25<00:05,  1.08it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:26<00:05,  1.02s/it]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:27<00:03,  1.01it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:28<00:02,  1.05it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:29<00:01,  1.04it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.06it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
            "Extracting Hidden States:  10%|▉         | 61/630 [22:36<4:54:21, 31.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1950 examples so far.Labels size: 20134\n",
            "end_idx 1984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:27,  1.12it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.07it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.06it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:23,  1.20it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:23,  1.14it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.12it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.11it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.09it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.08it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.08it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:09<00:18,  1.12it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:18,  1.06it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:17,  1.09it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.11it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.07it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:15,  1.06it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.09it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.10it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:11,  1.10it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:10,  1.10it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.06it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.07it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.04it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.07it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.07it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.11it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.12it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.13it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.10it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.14it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.12it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 1982 examples so far.Labels size: 20134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:  10%|▉         | 62/630 [23:06<4:50:44, 30.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end_idx 2016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:29,  1.06it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.06it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.07it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:24,  1.12it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:22,  1.19it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:25,  1.02it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.04it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:23,  1.02it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.04it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.05it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:20,  1.00it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.06it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.09it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.11it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:18,  1.09s/it]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:15,  1.00it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:14,  1.05it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.13it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:19<00:16,  1.26s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:20<00:14,  1.23s/it]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:21<00:12,  1.11s/it]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:22<00:10,  1.07s/it]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:08,  1.00it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:07,  1.03it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:24<00:06,  1.03it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:25<00:05,  1.04it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:26<00:04,  1.06it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:27<00:03,  1.08it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:28<00:02,  1.06it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:29<00:01,  1.06it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:30<00:00,  1.15it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:31<00:00,  1.03it/s]\n",
            "Extracting Hidden States:  10%|█         | 63/630 [23:38<4:53:55, 31.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2014 examples so far.Labels size: 20134\n",
            "end_idx 2048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:39,  1.26s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:27,  1.07it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:24,  1.17it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:23,  1.18it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:22,  1.19it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:22,  1.16it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.12it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.05it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.05it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.06it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.06it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.06it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:18,  1.05it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.09it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.11it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.12it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.08it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.10it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:11,  1.10it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:10,  1.12it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.06it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.07it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.01it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.01it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.04it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.04it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.05it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.14it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.13it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.14it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.14it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.09it/s]\n",
            "Extracting Hidden States:  10%|█         | 64/630 [24:08<4:51:10, 30.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2046 examples so far.Labels size: 20134\n",
            "end_idx 2080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:29,  1.04it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:26,  1.13it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.10it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:25,  1.12it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.11it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.07it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:26,  1.07s/it]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:24,  1.03s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.02it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.02it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:20,  1.03it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.05it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.06it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.02it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.11it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:14,  1.14it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:12,  1.16it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.14it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:15,  1.19s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:13,  1.11s/it]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:11,  1.02s/it]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:10,  1.03s/it]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:22<00:08,  1.01it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:07,  1.02it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:24<00:06,  1.05it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:25<00:05,  1.08it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.12it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.08it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.07it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.05it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.10it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2078 examples so far.Labels size: 20134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:  10%|█         | 65/630 [24:39<4:52:17, 31.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end_idx 2112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:22,  1.37it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:24,  1.21it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.09it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:23,  1.17it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:23,  1.14it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:22,  1.16it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.12it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.12it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.06it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:08<00:19,  1.11it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:09<00:18,  1.13it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:17,  1.13it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:17,  1.11it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:15,  1.15it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:14,  1.21it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:13<00:13,  1.19it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:14<00:12,  1.22it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:15<00:11,  1.18it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:16<00:11,  1.16it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:17<00:10,  1.10it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:18<00:10,  1.09it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:19<00:08,  1.13it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:20<00:08,  1.11it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:21<00:07,  1.14it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:21<00:06,  1.12it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:22<00:05,  1.11it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:23<00:04,  1.14it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:24<00:03,  1.14it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:25<00:02,  1.07it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:26<00:01,  1.05it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:27<00:00,  1.07it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:28<00:00,  1.12it/s]\n",
            "Extracting Hidden States:  10%|█         | 66/630 [25:09<4:46:57, 30.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2110 examples so far.Labels size: 20134\n",
            "end_idx 2144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:30,  1.03it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:26,  1.13it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:24,  1.19it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:23,  1.20it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.09it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.07it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.10it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.11it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:20,  1.13it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.02it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:20,  1.01it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:19,  1.04it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:18,  1.02it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.02it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:16,  1.03it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:15,  1.03it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:14,  1.07it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.08it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.04it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.04it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.08it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:08,  1.12it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:09,  1.02s/it]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.00it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.06it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.09it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.12it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.03it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.04it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.09it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.10it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
            "Extracting Hidden States:  11%|█         | 67/630 [25:40<4:47:20, 30.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2142 examples so far.Labels size: 20134\n",
            "end_idx 2176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:26,  1.18it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:25,  1.15it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.11it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.07it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.09it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.07it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.10it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.11it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.03it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.05it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.05it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.07it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.07it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.11it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:16,  1.02it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:15,  1.03it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:14,  1.06it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.08it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.08it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:10,  1.10it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.05it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.04it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.06it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.04it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.06it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.14it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.10it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.08it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.12it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.20it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.16it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.09it/s]\n",
            "Extracting Hidden States:  11%|█         | 68/630 [26:10<4:45:50, 30.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2174 examples so far.Labels size: 20134\n",
            "end_idx 2208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:20,  1.48it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:24,  1.23it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:25,  1.14it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:24,  1.15it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:23,  1.16it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:22,  1.17it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.09it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.08it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.07it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:24,  1.11s/it]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:23,  1.12s/it]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:21,  1.06s/it]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:18,  1.00it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.06it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:16,  1.05it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:14,  1.09it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:13,  1.09it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.12it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:11,  1.12it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:10,  1.12it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.09it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.10it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.09it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.12it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.10it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.08it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.06it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:04,  1.15s/it]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:03,  1.06s/it]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:02,  1.03s/it]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:01,  1.08s/it]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
            "Extracting Hidden States:  11%|█         | 69/630 [26:41<4:48:20, 30.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2206 examples so far.Labels size: 20134\n",
            "end_idx 2240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:31,  1.01s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:31,  1.04s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:03<00:30,  1.05s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:04<00:28,  1.01s/it]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:05<00:31,  1.16s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:06<00:28,  1.08s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:07<00:25,  1.03s/it]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:08<00:28,  1.20s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:09<00:25,  1.12s/it]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:11<00:25,  1.15s/it]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:12<00:22,  1.08s/it]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:13<00:21,  1.07s/it]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:14<00:23,  1.24s/it]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:15<00:20,  1.16s/it]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:16<00:18,  1.09s/it]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:17<00:16,  1.01s/it]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:18<00:14,  1.01it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:19<00:13,  1.02it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:20<00:12,  1.05it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:21<00:11,  1.03it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:22<00:12,  1.11s/it]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:23<00:10,  1.05s/it]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:24<00:09,  1.03s/it]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:25<00:07,  1.03it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:26<00:06,  1.04it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:27<00:05,  1.05it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:28<00:04,  1.06it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:29<00:03,  1.05it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:30<00:02,  1.06it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:31<00:01,  1.06it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:31<00:00,  1.06it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:32<00:00,  1.03s/it]\n",
            "Extracting Hidden States:  11%|█         | 70/630 [27:15<4:56:19, 31.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2238 examples so far.Labels size: 20134\n",
            "end_idx 2272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:27,  1.13it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:27,  1.07it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.07it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.07it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.07it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:22,  1.18it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.13it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:20,  1.15it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:20,  1.13it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.08it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:09<00:18,  1.11it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:18,  1.10it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:17,  1.12it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:15,  1.14it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:14,  1.16it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.07it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:14,  1.04it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:13,  1.04it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.05it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.07it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.07it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.00it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.01it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.02it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.02it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.03it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.04it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:04,  1.04s/it]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.02it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.04it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.06it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
            "Extracting Hidden States:  11%|█▏        | 71/630 [27:46<4:53:15, 31.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2270 examples so far.Labels size: 20134\n",
            "end_idx 2304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:28,  1.11it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.04it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:24,  1.17it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:25,  1.09it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.06it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.06it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.07it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:23,  1.02it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.04it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.08it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.08it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.07it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.06it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.06it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.09it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.09it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.11it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.08it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:11,  1.11it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:10,  1.10it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:09,  1.10it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.08it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.06it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.05it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.05it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.16it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.18it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.13it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.11it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.13it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.10it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.09it/s]\n",
            "Extracting Hidden States:  11%|█▏        | 72/630 [28:17<4:49:46, 31.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2302 examples so far.Labels size: 20134\n",
            "end_idx 2336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:28,  1.09it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.07it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.06it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.05it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.05it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.07it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.07it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.10it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:20,  1.11it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.04it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:18,  1.12it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.10it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.09it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.08it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:16,  1.06it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:15,  1.07it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.09it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.15it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:11,  1.12it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:10,  1.20it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:09,  1.18it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:19<00:08,  1.16it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:20<00:07,  1.14it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:21<00:07,  1.10it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:22<00:06,  1.06it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.07it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.03it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.00it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.11it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.08it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.02it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.07it/s]\n",
            "Extracting Hidden States:  12%|█▏        | 73/630 [28:47<4:47:39, 30.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2334 examples so far.Labels size: 20134\n",
            "end_idx 2368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:29,  1.06it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:27,  1.11it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.10it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.06it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.07it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.10it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.10it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.08it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.09it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.08it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.07it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.07it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:17,  1.10it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.09it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.11it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:13,  1.18it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:12,  1.19it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:11,  1.24it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:16<00:10,  1.21it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:17<00:10,  1.17it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.03it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:19<00:09,  1.05it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:20<00:08,  1.06it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:21<00:07,  1.08it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:22<00:06,  1.08it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:06,  1.03s/it]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:05,  1.01s/it]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:04,  1.01s/it]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.00it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.08it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.09it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.09it/s]\n",
            "Extracting Hidden States:  12%|█▏        | 74/630 [29:17<4:45:27, 30.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2366 examples so far.Labels size: 20134\n",
            "end_idx 2400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:31,  1.01s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:30,  1.01s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:28,  1.02it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:27,  1.02it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.04it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.09it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.10it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.09it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.03it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.08it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.07it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.10it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.10it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.09it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.09it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.08it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.07it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.09it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:11,  1.09it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.09it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.10it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.10it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.10it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.12it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.11it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.09it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.06it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.17it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.15it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.20it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.15it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.09it/s]\n",
            "Extracting Hidden States:  12%|█▏        | 75/630 [29:47<4:42:42, 30.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2398 examples so far.Labels size: 20134\n",
            "end_idx 2432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:32,  1.04s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:35,  1.17s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:03<00:30,  1.06s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:04<00:28,  1.01s/it]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:05<00:26,  1.02it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:06<00:25,  1.02it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:24,  1.04it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.07it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.09it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.04it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.08it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.08it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.08it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.08it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.09it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:14,  1.09it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:14,  1.07it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:13,  1.07it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:12,  1.07it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:11,  1.07it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.06it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.06it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.09it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:06,  1.17it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.09it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.06it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.05it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.08it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.08it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.09it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.06it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
            "Extracting Hidden States:  12%|█▏        | 76/630 [30:19<4:43:35, 30.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2430 examples so far.Labels size: 20134\n",
            "end_idx 2464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:27,  1.15it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:25,  1.16it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:25,  1.12it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:25,  1.10it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:28,  1.04s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:26,  1.00s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:24,  1.04it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.07it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.07it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.06it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.06it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.07it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.11it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.09it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.09it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.09it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.14it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.12it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:11,  1.10it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.08it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.08it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:08,  1.14it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:07,  1.15it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:21<00:06,  1.15it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:22<00:06,  1.13it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.10it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.08it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:04,  1.10s/it]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:03,  1.06s/it]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:02,  1.00s/it]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.05it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2462 examples so far.Labels size: 20134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:  12%|█▏        | 77/630 [30:49<4:42:30, 30.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end_idx 2496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:27,  1.13it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:25,  1.17it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:24,  1.19it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.06it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:26,  1.03it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:25,  1.02it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.06it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.06it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.06it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.04it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.06it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:19,  1.02it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:18,  1.04it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.05it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.11it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.08it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.07it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:14,  1.01s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:13,  1.07s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:13,  1.10s/it]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:10,  1.03it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:09,  1.06it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.10it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:23<00:08,  1.05s/it]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:24<00:07,  1.01s/it]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:25<00:05,  1.03it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:26<00:04,  1.03it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:27<00:03,  1.01it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.03it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.06it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.04it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2494 examples so far.Labels size: 20134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:  12%|█▏        | 78/630 [31:20<4:43:58, 30.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end_idx 2528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:29,  1.07it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.07it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.07it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:25,  1.10it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.08it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.11it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.09it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.09it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.05it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.07it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:18,  1.14it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:17,  1.15it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:17,  1.12it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:15,  1.17it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.12it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.11it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.10it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.09it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.06it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:10,  1.14it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:18<00:09,  1.15it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:19<00:08,  1.23it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:20<00:07,  1.19it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:21<00:06,  1.19it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:22<00:06,  1.16it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.13it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.14it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:24<00:03,  1.13it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:25<00:02,  1.11it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:26<00:01,  1.11it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:27<00:00,  1.08it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:28<00:00,  1.11it/s]\n",
            "Extracting Hidden States:  13%|█▎        | 79/630 [31:50<4:39:57, 30.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2526 examples so far.Labels size: 20134\n",
            "end_idx 2560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:28,  1.10it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:27,  1.10it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.09it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.08it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.04it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:26,  1.01s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.07it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.10it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.07it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.08it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.07it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:19,  1.01it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:18,  1.03it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.03it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:16,  1.04it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:15,  1.06it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:14,  1.06it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:13,  1.05it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:11,  1.09it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.06it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.05it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.07it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.07it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.10it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.09it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.06it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.10it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.09it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.12it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.15it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.12it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.07it/s]\n",
            "Extracting Hidden States:  13%|█▎        | 80/630 [32:21<4:39:42, 30.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2558 examples so far.Labels size: 20134\n",
            "end_idx 2592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:26,  1.15it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:25,  1.16it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:24,  1.17it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:25,  1.10it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.08it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.08it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.08it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.07it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.09it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.09it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:09<00:18,  1.12it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:18,  1.10it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:17,  1.10it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.08it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.08it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.12it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.14it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.12it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:11,  1.13it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.07it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.07it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.09it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:20<00:08,  1.09it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.01it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.03it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.04it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.03it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:04,  1.03s/it]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:03,  1.03s/it]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:02,  1.01s/it]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.02it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [01:14<00:00,  2.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2590 examples so far.Labels size: 20134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting Hidden States:  13%|█▎        | 81/630 [33:36<6:41:35, 43.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end_idx 2624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:31,  1.01s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.04it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:03<00:29,  1.03s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:04<00:28,  1.03s/it]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:05<00:27,  1.02s/it]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:25,  1.02it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:07<00:25,  1.00s/it]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:23,  1.02it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.05it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.04it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:20,  1.05it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:19,  1.05it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.07it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.06it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:16,  1.02it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:15,  1.02it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:14,  1.03it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:13,  1.04it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:12,  1.07it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:19<00:10,  1.10it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:20<00:10,  1.10it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:21<00:09,  1.09it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.11it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.09it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.05it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.08it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.06it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.05it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.05it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.07it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.07it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
            "Extracting Hidden States:  13%|█▎        | 82/630 [34:07<6:06:42, 40.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2622 examples so far.Labels size: 20134\n",
            "end_idx 2656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:23,  1.31it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:25,  1.16it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:25,  1.13it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:24,  1.14it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.11it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.10it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.09it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.09it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.08it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.06it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.07it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:18,  1.08it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:16,  1.16it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:14,  1.22it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:14,  1.17it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.11it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:14,  1.06it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:13,  1.06it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:11,  1.09it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:17<00:10,  1.19it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:18<00:09,  1.16it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:19<00:08,  1.13it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:20<00:08,  1.11it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:21<00:07,  1.08it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:22<00:05,  1.17it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.12it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.09it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:24<00:03,  1.16it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:25<00:02,  1.15it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:26<00:01,  1.11it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:27<00:00,  1.11it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:28<00:00,  1.12it/s]\n",
            "Extracting Hidden States:  13%|█▎        | 83/630 [34:37<5:36:44, 36.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2654 examples so far.Labels size: 20134\n",
            "end_idx 2688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:19,  1.55it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:24,  1.24it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:25,  1.14it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:24,  1.16it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:23,  1.13it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.12it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.11it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:06<00:21,  1.13it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:07<00:20,  1.11it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.01it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:20,  1.03it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:18,  1.11it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:17,  1.08it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.07it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.08it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:15,  1.01it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.11it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.10it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:11,  1.12it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:10,  1.12it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:18<00:09,  1.14it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.07it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.01it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.03it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:22<00:06,  1.06it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.09it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.09it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.10it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.09it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.03it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.05it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.09it/s]\n",
            "Extracting Hidden States:  13%|█▎        | 84/630 [35:07<5:18:11, 34.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2686 examples so far.Labels size: 20134\n",
            "end_idx 2720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:32,  1.05s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:29,  1.01it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:24,  1.17it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:24,  1.14it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.11it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.10it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.05it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.09it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.09it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:08<00:18,  1.19it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:09<00:17,  1.17it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:18,  1.07it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:18,  1.04it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:17,  1.05it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:16,  1.06it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.07it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.08it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:12,  1.12it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:10,  1.22it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:10,  1.15it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:09,  1.13it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.06it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.04it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:21<00:07,  1.08it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:22<00:06,  1.13it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.13it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.14it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.11it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:03,  1.03s/it]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.02it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.04it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.09it/s]\n",
            "Extracting Hidden States:  13%|█▎        | 85/630 [35:38<5:05:46, 33.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2718 examples so far.Labels size: 20134\n",
            "end_idx 2752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:28,  1.08it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:27,  1.07it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:25,  1.14it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:25,  1.10it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:23,  1.14it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:22,  1.16it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:21,  1.14it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.09it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.09it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:20,  1.08it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:09<00:19,  1.10it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:17,  1.12it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:16,  1.14it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.07it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:16,  1.06it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:15,  1.05it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:14,  1.06it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:13,  1.06it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.06it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.06it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.03it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:10,  1.02s/it]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:09,  1.00s/it]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.04it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:07,  1.03s/it]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.00it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.02it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.04it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.03it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.11it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.12it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.07it/s]\n",
            "Extracting Hidden States:  14%|█▎        | 86/630 [36:08<4:57:39, 32.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2750 examples so far.Labels size: 20134\n",
            "end_idx 2784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:28,  1.08it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:28,  1.06it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.05it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.07it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.07it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:22,  1.15it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:22,  1.14it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:21,  1.11it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:20,  1.12it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:08<00:18,  1.17it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:19,  1.07it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:18,  1.10it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:17,  1.09it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.10it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:15,  1.10it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:14,  1.07it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:16,  1.11s/it]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:14,  1.06s/it]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:13,  1.02s/it]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.02it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.07it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.07it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.08it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.09it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.11it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.10it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.14it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.14it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.11it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.12it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.07it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.07it/s]\n",
            "Extracting Hidden States:  14%|█▍        | 87/630 [36:41<4:57:13, 32.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2782 examples so far.Labels size: 20134\n",
            "end_idx 2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:29,  1.05it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:27,  1.11it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.11it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:25,  1.09it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.09it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.04it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:24,  1.04it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:09<00:40,  1.71s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:10<00:33,  1.46s/it]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:11<00:28,  1.29s/it]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:12<00:24,  1.19s/it]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:13<00:22,  1.11s/it]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:14<00:20,  1.06s/it]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:15<00:19,  1.08s/it]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:16<00:17,  1.04s/it]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:17<00:15,  1.04it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:18<00:14,  1.06it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:19<00:13,  1.00it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:20<00:12,  1.02it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:21<00:11,  1.02it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:22<00:10,  1.02it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:23<00:09,  1.03it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:24<00:08,  1.04it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:25<00:07,  1.08it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:26<00:06,  1.05it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:26<00:05,  1.08it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:27<00:04,  1.05it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:28<00:03,  1.06it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:29<00:02,  1.08it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:30<00:01,  1.10it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:31<00:00,  1.04it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:32<00:00,  1.02s/it]\n",
            "Extracting Hidden States:  14%|█▍        | 88/630 [37:15<4:58:19, 33.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2814 examples so far.Labels size: 20134\n",
            "end_idx 2848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:32,  1.04s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:27,  1.10it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.08it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.04it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:24,  1.12it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.07it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:25,  1.02s/it]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:22,  1.05it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:21,  1.05it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.02it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:20,  1.04it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.07it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:18,  1.03it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:17,  1.03it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:16,  1.03it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:15,  1.05it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:13,  1.07it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:13,  1.07it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:18<00:11,  1.09it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.07it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.08it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:09,  1.08it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:07,  1.14it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.12it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.13it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.06it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.07it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:26<00:03,  1.06it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:27<00:02,  1.08it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:28<00:01,  1.10it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:29<00:00,  1.07it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.07it/s]\n",
            "Extracting Hidden States:  14%|█▍        | 89/630 [37:46<4:51:42, 32.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2846 examples so far.Labels size: 20134\n",
            "end_idx 2880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:01<00:33,  1.07s/it]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:02<00:32,  1.08s/it]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:03<00:29,  1.01s/it]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.07it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.08it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:23,  1.10it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:20,  1.21it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:20,  1.18it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:19,  1.15it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:19,  1.12it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:09<00:18,  1.13it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:17,  1.15it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:17,  1.11it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.10it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:13<00:16,  1.04it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:14<00:15,  1.06it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:13,  1.10it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:16<00:11,  1.19it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:11,  1.15it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.06it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:18<00:09,  1.16it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:19<00:08,  1.17it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:20<00:08,  1.11it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:21<00:07,  1.05it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:22<00:06,  1.06it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.09it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.12it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.11it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.18it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.11it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:27<00:00,  1.17it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:28<00:00,  1.11it/s]\n",
            "Extracting Hidden States:  14%|█▍        | 90/630 [38:15<4:44:10, 31.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2878 examples so far.Labels size: 20134\n",
            "end_idx 2912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:20,  1.50it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:24,  1.23it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:22,  1.28it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:22,  1.25it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:22,  1.20it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:04<00:22,  1.18it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:05<00:21,  1.16it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:06<00:21,  1.14it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:07<00:20,  1.11it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:08<00:18,  1.20it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:09<00:17,  1.17it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:17,  1.14it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:11<00:16,  1.12it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:12<00:16,  1.09it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:12<00:15,  1.11it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:13<00:14,  1.10it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:14<00:13,  1.09it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:15<00:12,  1.10it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:16<00:11,  1.10it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:17<00:10,  1.12it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:18<00:10,  1.09it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:19<00:09,  1.08it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:20<00:08,  1.07it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:21<00:07,  1.10it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:22<00:06,  1.09it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:23<00:05,  1.06it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:24<00:04,  1.06it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:24<00:03,  1.11it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:25<00:02,  1.21it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:26<00:01,  1.17it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:27<00:00,  1.15it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:28<00:00,  1.14it/s]\n",
            "Extracting Hidden States:  14%|█▍        | 91/630 [38:44<4:36:27, 30.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2910 examples so far.Labels size: 20134\n",
            "end_idx 2944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:25,  1.23it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:26,  1.11it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:26,  1.09it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:25,  1.10it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.06it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:05<00:24,  1.08it/s]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:06<00:23,  1.08it/s]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:19,  1.21it/s]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:07<00:18,  1.24it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:08<00:18,  1.17it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:09<00:18,  1.15it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:10<00:17,  1.16it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:21,  1.15s/it]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:19,  1.08s/it]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:17,  1.03s/it]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:16,  1.01s/it]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:15<00:14,  1.05it/s]\u001b[A\n",
            "Loading Images:  56%|█████▋    | 18/32 [00:17<00:13,  1.02it/s]\u001b[A\n",
            "Loading Images:  59%|█████▉    | 19/32 [00:17<00:12,  1.03it/s]\u001b[A\n",
            "Loading Images:  62%|██████▎   | 20/32 [00:18<00:11,  1.07it/s]\u001b[A\n",
            "Loading Images:  66%|██████▌   | 21/32 [00:19<00:10,  1.07it/s]\u001b[A\n",
            "Loading Images:  69%|██████▉   | 22/32 [00:20<00:08,  1.12it/s]\u001b[A\n",
            "Loading Images:  72%|███████▏  | 23/32 [00:21<00:08,  1.08it/s]\u001b[A\n",
            "Loading Images:  75%|███████▌  | 24/32 [00:22<00:07,  1.08it/s]\u001b[A\n",
            "Loading Images:  78%|███████▊  | 25/32 [00:23<00:06,  1.07it/s]\u001b[A\n",
            "Loading Images:  81%|████████▏ | 26/32 [00:24<00:05,  1.09it/s]\u001b[A\n",
            "Loading Images:  84%|████████▍ | 27/32 [00:25<00:04,  1.09it/s]\u001b[A\n",
            "Loading Images:  88%|████████▊ | 28/32 [00:25<00:03,  1.20it/s]\u001b[A\n",
            "Loading Images:  91%|█████████ | 29/32 [00:26<00:02,  1.24it/s]\u001b[A\n",
            "Loading Images:  94%|█████████▍| 30/32 [00:27<00:01,  1.19it/s]\u001b[A\n",
            "Loading Images:  97%|█████████▋| 31/32 [00:28<00:00,  1.18it/s]\u001b[A\n",
            "Loading Images: 100%|██████████| 32/32 [00:29<00:00,  1.09it/s]\n",
            "Extracting Hidden States:  15%|█▍        | 92/630 [39:14<4:33:55, 30.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_error True\n",
            "text embeddings have shape: torch.Size([32, 512]) and img embeddings have shape: torch.Size([32, 512])\n",
            "combined hidden states now has shape: torch.Size([32, 2, 512])\n",
            "Processed 2942 examples so far.Labels size: 20134\n",
            "end_idx 2976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading Images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Loading Images:   3%|▎         | 1/32 [00:00<00:30,  1.02it/s]\u001b[A\n",
            "Loading Images:   6%|▋         | 2/32 [00:01<00:29,  1.03it/s]\u001b[A\n",
            "Loading Images:   9%|▉         | 3/32 [00:02<00:27,  1.04it/s]\u001b[A\n",
            "Loading Images:  12%|█▎        | 4/32 [00:03<00:26,  1.07it/s]\u001b[A\n",
            "Loading Images:  16%|█▌        | 5/32 [00:04<00:25,  1.07it/s]\u001b[A\n",
            "Loading Images:  19%|█▉        | 6/32 [00:06<00:28,  1.10s/it]\u001b[A\n",
            "Loading Images:  22%|██▏       | 7/32 [00:07<00:26,  1.05s/it]\u001b[A\n",
            "Loading Images:  25%|██▌       | 8/32 [00:07<00:24,  1.00s/it]\u001b[A\n",
            "Loading Images:  28%|██▊       | 9/32 [00:08<00:22,  1.04it/s]\u001b[A\n",
            "Loading Images:  31%|███▏      | 10/32 [00:09<00:21,  1.03it/s]\u001b[A\n",
            "Loading Images:  34%|███▍      | 11/32 [00:10<00:20,  1.05it/s]\u001b[A\n",
            "Loading Images:  38%|███▊      | 12/32 [00:11<00:18,  1.06it/s]\u001b[A\n",
            "Loading Images:  41%|████      | 13/32 [00:12<00:17,  1.06it/s]\u001b[A\n",
            "Loading Images:  44%|████▍     | 14/32 [00:13<00:16,  1.08it/s]\u001b[A\n",
            "Loading Images:  47%|████▋     | 15/32 [00:14<00:15,  1.09it/s]\u001b[A\n",
            "Loading Images:  50%|█████     | 16/32 [00:15<00:14,  1.09it/s]\u001b[A\n",
            "Loading Images:  53%|█████▎    | 17/32 [00:16<00:13,  1.09it/s]\u001b[A"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6whwj0ZTgcl"
      },
      "source": [
        "## Initialize Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83yGoUSPWi44"
      },
      "outputs": [],
      "source": [
        "def process_labels(labels):\n",
        "  \"\"\" Goes through all labels and converts from a list of strings to a pytorch tensor, 0 if negative, 1 is positive\n",
        "  \"\"\"\n",
        "  label_map = {\"negative\": 0, \"positive\": 1}\n",
        "  encoded_labels = [label_map[label] for label in labels]\n",
        "  return torch.tensor(encoded_labels, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpqFLjsLtNZL"
      },
      "outputs": [],
      "source": [
        "def extract_cls_emeddings(encoder_emeddings):\n",
        "  text_cls_emeddings = encoder_emeddings[:, 0,:]\n",
        "  image_cls_emeddings = encoder_emeddings[:, 77,:]\n",
        "  return text_cls_emeddings, image_cls_emeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
        "\n",
        "class MultiModalDataset(Dataset):\n",
        "  def __init__(self, embeddings, sentiment_labels):\n",
        "    self.embeddings = embeddings\n",
        "    self.labels = sentiment_labels\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\" Returns the number of samples in the dataset.\n",
        "    \"\"\"\n",
        "    return int(len(self.labels))\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    try:\n",
        "      embedding = self.embeddings[idx]\n",
        "      label = self.labels[idx]\n",
        "      return embedding, label\n",
        "    except Exception as e:\n",
        "      print(f\"Can't get sample\")\n",
        "      random_idx = torch.randint(0, len(self.embeddings), (1,)).item()\n",
        "      return self.__getitem__(random_idx)"
      ],
      "metadata": {
        "id": "0Nr1JXmA5LL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " \\\\"
      ],
      "metadata": {
        "id": "MVOTEZtmcEjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\\"
      ],
      "metadata": {
        "id": "qAGiQ5hwcEqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\\"
      ],
      "metadata": {
        "id": "CBp9vh9BcEt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\\"
      ],
      "metadata": {
        "id": "4e0YZHaycExu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\\"
      ],
      "metadata": {
        "id": "3OWZjiz1cE17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Start Here"
      ],
      "metadata": {
        "id": "XICIKjYNb_10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data from saved"
      ],
      "metadata": {
        "id": "SOha7cHB2Agt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset_test = False"
      ],
      "metadata": {
        "id": "4Yfgggs_2ETJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if subset_test:\n",
        "  embeddings_path = '/content/drive/MyDrive/MASAD_pivot/mme_1k.pt'\n",
        "  labels_path = '/content/drive/MyDrive/MASAD_pivot/labels_1k.pt'\n",
        "  print(\"Running on subset for testing.\")\n",
        "else:\n",
        "  embeddings_path = '/content/drive/MyDrive/MASAD_pivot/mme_20k.pt'\n",
        "  labels_path = '/content/drive/MyDrive/MASAD_pivot/labels_20k.pt'\n",
        "  print(\"Running on full, balanced data for final results.\")"
      ],
      "metadata": {
        "id": "z1LbegNN2WEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec97ce84-34a7-4b5b-8649-97b6ee930480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on full, balanced data for final results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torch.load: https://pytorch.org/docs/stable/generated/torch.load.html \\\\\n",
        "random_split: https://discuss.pytorch.org/t/how-to-split-dataset-into-test-and-validation-sets/33987/3"
      ],
      "metadata": {
        "id": "rM741sYX4rWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = torch.load(embeddings_path)\n",
        "labels = torch.load(labels_path)\n",
        "\n",
        "print(embeddings.size())\n",
        "print(len(labels))"
      ],
      "metadata": {
        "id": "gr5tzWKm3mb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "224cbea6-4457-455f-98d1-6d7be4512598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-408fb416abce>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  embeddings = torch.load(embeddings_path)\n",
            "<ipython-input-30-408fb416abce>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  labels = torch.load(labels_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([19982, 2, 512])\n",
            "19982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Init dataset object for dataloader and get seeded random split"
      ],
      "metadata": {
        "id": "O6cAAxeACAwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using generator seed for consistency\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "\n",
        "# Init dataset class for dataloaders later\n",
        "dataset = MultiModalDataset(embeddings, labels)\n",
        "\n",
        "split = 0.8\n",
        "\n",
        "# get splits\n",
        "train_split = int(split * dataset.__len__())\n",
        "test_split = int(dataset.__len__() - train_split)\n",
        "\n",
        "# Debugging size issues\n",
        "print(\"Successful split\" if dataset.__len__() == (train_split + test_split) else f\"Split failed: train len = {train_split}, test len = {test_split}\")\n",
        "\n",
        "# Get train and test set\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [train_split, test_split], generator=generator)"
      ],
      "metadata": {
        "id": "vSHBTXK86y9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e508e7ed-4b20-4ae8-9be0-5401af42f553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful split\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "# DataLoaders for easy iter\n",
        "train_loader = DataLoader(train_set, batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "kBdot6QA9A6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization"
      ],
      "metadata": {
        "id": "wFVt6GzC_pE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from PIL import ImageColor\n",
        "df = pd.read_pickle(save_path_raw)\n",
        "print(df.keys())\n",
        "image_paths = df['image_path']\n",
        "labels = df['label']\n",
        "images = []\n",
        "\n",
        "nvis = 4 # how many images to visualize\n",
        "for i in range(nvis):\n",
        "  im = Image.open(image_paths[i])\n",
        "  images.append(im)\n",
        "\n",
        "print(f'attempting to visualize {len(images)} with matplotlib')\n",
        "visualize_a_few_images(images, labels[:nvis])"
      ],
      "metadata": {
        "id": "D-sTJqGU_oJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWtM432nTk-L"
      },
      "source": [
        "#Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-8mS5BUOB-8"
      },
      "outputs": [],
      "source": [
        "class SequenceWiseTransformer(nn.Module):\n",
        "    def __init__(self, d_model=512, nhead=8, num_layers=4, dim_feedforward=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "      e = self.transformer_encoder(x)\n",
        "      return e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5W9mL0fU4OJe"
      },
      "outputs": [],
      "source": [
        "class KeylessAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(KeylessAttention, self).__init__()\n",
        "        self.W = nn.Parameter(torch.empty(hidden_size))\n",
        "        # Use Xavier rather than uniform for better inits\n",
        "        nn.init.xavier_uniform_(self.W.unsqueeze(0))\n",
        "\n",
        "    def forward(self, text_emb, im_emb):\n",
        "        # Have pivoted to using entire sequence - level embeddings\n",
        "        text_attn = torch.matmul(text_emb, self.W)\n",
        "        im_attn = torch.matmul(im_emb, self.W)\n",
        "\n",
        "        # Functional softmax is more numerically stable\n",
        "        scores = torch.stack([text_attn, im_attn], dim=1)\n",
        "        weights = F.softmax(scores, dim=1)\n",
        "        w_text = weights[:, 0].unsqueeze(1)\n",
        "        w_img = weights[:, 1].unsqueeze(1)\n",
        "\n",
        "        # Aggregate the embeddings\n",
        "        combined_emb = w_img * im_emb + w_text * text_emb\n",
        "        return combined_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQOcxvhF4U_B"
      },
      "outputs": [],
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, d_model=512, num_classes=1):\n",
        "        super().__init__()\n",
        "        # hidden layer size to 128, then 32, then 1\n",
        "        self.linear1 = nn.Linear(d_model, 128)\n",
        "        self.linear2 = nn.Linear(128, 32)\n",
        "        self.linear3 = nn.Linear(32, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Tried normalization and it didn't really help\n",
        "        # Adding dropout due to overfitting\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass_1 = self.linear1(x)\n",
        "        basic_activation_1 = self.relu(pass_1)\n",
        "        dropout_1 = self.dropout(basic_activation_1)\n",
        "        pass_2 = self.linear2(dropout_1)\n",
        "        basic_activation_2 = self.relu(pass_2)\n",
        "        dropout_2 = self.dropout(basic_activation_2)\n",
        "        x = self.linear3(dropout_2)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwHXAKlQ4ZQZ"
      },
      "outputs": [],
      "source": [
        "class FullModel(nn.Module):\n",
        "    def __init__(self, transformer, keyless_attention, classifier):\n",
        "        super(FullModel, self).__init__()\n",
        "        self.transformer = transformer\n",
        "        self.keyless_attention = keyless_attention\n",
        "        self.classifier = classifier\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded_embeddings = self.transformer(x) # Should be size [B, 2, D]\n",
        "        combined_emb = self.keyless_attention(encoded_embeddings[:, 0, :], encoded_embeddings[:, 1, :])\n",
        "        logits = self.classifier(combined_emb)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMNPW-UIURBB"
      },
      "source": [
        "#Train & Test Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding BCEWithLogitsLoss vs CrossEntropyLoss: https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-pytorch-loss-functions.md\n",
        "\n",
        "\"This version is more numerically stable than using a plain Sigmoid followed by a BCELoss as, by combining the operations into one layer, we take advantage of the log-sum-exp trick for numerical stability.\""
      ],
      "metadata": {
        "id": "A-oWyCaC_2V8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4OyJzjBpAnG"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, loss_fn, epoch,writer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Use tqdm for progress\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch} Training\", leave=False)\n",
        "\n",
        "    # Do not detach\n",
        "    for batch_idx, (data, label) in enumerate(pbar):\n",
        "        data, label = data.to(device), label.to(device).unsqueeze(1).float()\n",
        "\n",
        "        # Forward Pass\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, label)\n",
        "\n",
        "        # Backward Pass & Optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Increment loss and update pbar for tqdm\n",
        "        running_loss += loss.item()\n",
        "        pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    writer.add_scalar('Loss/Train', avg_loss, epoch)\n",
        "\n",
        "\n",
        "    print(f'\\nEpoch {epoch} Training Loss: {avg_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxJctBD8qKuU"
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader, loss_fn, epoch,writer):\n",
        "    print(f'*** RUNNING TEST FUNCTION ***')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Bug - removed \"detach()\"\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, label) in enumerate(tqdm(test_loader, desc=\"Testing\", leave=False)):\n",
        "            data, label = data.to(device), label.to(device).unsqueeze(1).float()\n",
        "\n",
        "            # Get prediction; calculate test loss & # of correct predictions\n",
        "            output = model(data)\n",
        "            loss = loss_fn(output, label)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            probs = torch.sigmoid(output)\n",
        "            preds = (probs >= 0.5).float()\n",
        "\n",
        "            # Had to modify extended list due to format change\n",
        "            all_preds.extend(preds.cpu().numpy().flatten().tolist())\n",
        "            all_labels.extend(label.cpu().numpy().flatten().tolist())\n",
        "\n",
        "\n",
        "    # Use sklearn to do eval comps for us :)\n",
        "    avg_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100. * sum([p==l for p,l in zip(all_preds, all_labels)]) / len(all_labels)\n",
        "    precision = precision_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    roc = roc_auc_score(all_labels, all_preds)\n",
        "    writer.add_scalar('Loss/Test', avg_loss, epoch)\n",
        "    writer.add_scalar('Accuracy/Test', accuracy, epoch)\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch}: Test Loss: {avg_loss:.4f}  |  Accuracy {accuracy:.2f}  |  Precision {precision:.2f}  |  Recall {recall:.2f}  |  F1 {f1:.2f}  |  F1 {f1:.2f}  |  ROC-AUC {roc:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9CfFxc5TuPF"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Init components"
      ],
      "metadata": {
        "id": "GzQGMbkWDPfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = SequenceWiseTransformer()\n",
        "attention = KeylessAttention(hidden_size=512)\n",
        "classifier = ClassificationHead()\n",
        "model = FullModel(transformer, attention, classifier)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "gFaUul8SDMCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move all init params outside of train/test so they don't have to init on every train loop\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
        "# num_epochs = 20\n",
        "# num_warmup_steps =\n",
        "# total_steps = len(train_loader) *num_epochs\n",
        "# scheduler = get_linear_schedule_with_warmup(\n",
        "#     optimizer,\n",
        "#     num_warmup_steps=warmup_steps,  # Number of warmup steps\n",
        "#     num_training_steps=total_steps  # Total number of training steps\n",
        "# )\n",
        "\n",
        "# scheduler = StepLR(optimizer, step_size=5, gamma=0.1)"
      ],
      "metadata": {
        "id": "DcMg8vvuEe1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter(log_dir='/content/drive/My Drive/tensorboard_logs/experiment1')\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    print(f'beginning epoch: {epoch}')\n",
        "    train(model, device, train_loader, optimizer, loss_fn, epoch,writer)\n",
        "    test(model, device, test_loader, loss_fn, epoch,writer)\n",
        "    # scheduler.step()\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "b2chDlLEZJmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=\"/content/drive/My Drive/tensorboard_logs\""
      ],
      "metadata": {
        "id": "CgiZww7hrZ-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#End Here"
      ],
      "metadata": {
        "id": "H63kvfrDcMZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\\"
      ],
      "metadata": {
        "id": "z7kQv6qlcOnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\\"
      ],
      "metadata": {
        "id": "LRRLwmmvcOxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\\"
      ],
      "metadata": {
        "id": "LUVIf_RecO2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\\"
      ],
      "metadata": {
        "id": "8E6aJt8HcPDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\\"
      ],
      "metadata": {
        "id": "3w4AHiBacP2i"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2537d3571096468c8b9e23896660c5a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_256cdecb28e34dcb95e5a0f672d7330b",
              "IPY_MODEL_53e4ef3346e14065ada694b4a6173db7",
              "IPY_MODEL_5df256021a6b458180d68bff91903549"
            ],
            "layout": "IPY_MODEL_ba5b50f1647c4477bcccccefec5675c3"
          }
        },
        "256cdecb28e34dcb95e5a0f672d7330b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89492965e2054e08a80aa33adcea8062",
            "placeholder": "​",
            "style": "IPY_MODEL_fb3f9eeb5b6b476b8976ba56c96ad74e",
            "value": "config.json: 100%"
          }
        },
        "53e4ef3346e14065ada694b4a6173db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de0879b6f38a4613b702a48e559d883f",
            "max": 4186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fce334d9b8749649d857b956ce7b9bb",
            "value": 4186
          }
        },
        "5df256021a6b458180d68bff91903549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_513d5d7c65a1408d92dafa7c0a81ff8f",
            "placeholder": "​",
            "style": "IPY_MODEL_ad3b454d924c4617b7aa93aa0318da5c",
            "value": " 4.19k/4.19k [00:00&lt;00:00, 272kB/s]"
          }
        },
        "ba5b50f1647c4477bcccccefec5675c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89492965e2054e08a80aa33adcea8062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb3f9eeb5b6b476b8976ba56c96ad74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de0879b6f38a4613b702a48e559d883f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fce334d9b8749649d857b956ce7b9bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "513d5d7c65a1408d92dafa7c0a81ff8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad3b454d924c4617b7aa93aa0318da5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ee34ca9abd9426c9b9d765655e80050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9171cc60177d46079705c255401160d3",
              "IPY_MODEL_09e406636f5c47bb8e5d23bb523a54b2",
              "IPY_MODEL_8844ba5af1454712ac8a8a37ee42613c"
            ],
            "layout": "IPY_MODEL_f1e876af15bc4eb68e58cd5da8a57b5c"
          }
        },
        "9171cc60177d46079705c255401160d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8c5971753d24a68b848d1103cf5c3c4",
            "placeholder": "​",
            "style": "IPY_MODEL_ff5a6e5e609e4d338a186e90236eb398",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "09e406636f5c47bb8e5d23bb523a54b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11a42e85faa347e384022d33dce279c9",
            "max": 605247071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d904c5c41aab46acaf2625bb21a7392f",
            "value": 605247071
          }
        },
        "8844ba5af1454712ac8a8a37ee42613c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2d49455f23849dcb8c84a939ef3f4f1",
            "placeholder": "​",
            "style": "IPY_MODEL_38070900ea5948d68323e5fc833fa3e8",
            "value": " 605M/605M [00:02&lt;00:00, 247MB/s]"
          }
        },
        "f1e876af15bc4eb68e58cd5da8a57b5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8c5971753d24a68b848d1103cf5c3c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff5a6e5e609e4d338a186e90236eb398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11a42e85faa347e384022d33dce279c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d904c5c41aab46acaf2625bb21a7392f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2d49455f23849dcb8c84a939ef3f4f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38070900ea5948d68323e5fc833fa3e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}